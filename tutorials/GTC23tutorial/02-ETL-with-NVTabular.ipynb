{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cd5fcdb-f0af-48db-8bbe-2668df514d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ================================\n",
    "\n",
    "# Each user is responsible for checking the content of datasets and the\n",
    "# applicable licenses and determining if suitable for the intended use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e770427-d8c4-4b9e-8596-d89222c5f0e5",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Feature Engineering with MERLIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e33099a-adb8-4d50-b00a-fa83584f04fb",
   "metadata": {},
   "source": [
    "### 2.1. Feature Engineering on GPU with NVTabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf0d169-bf9f-48f3-b8be-230bb68fcf6e",
   "metadata": {},
   "source": [
    "Merlin [NVTabular](https://github.com/NVIDIA-Merlin/NVTabular) is a feature engineering and preprocessing library for tabular data that is designed to easily manipulate terabyte scale datasets and train deep learning (DL) based recommender systems. It provides high-level abstraction to simplify code and accelerates computation on the GPU using the RAPIDS Dask-cuDF library. If you want to learn more about NVTabular, we recommend the examples in the NVTabular GitHub [repository](https://github.com/NVIDIA-Merlin/NVTabular/tree/main/examples).\n",
    "\n",
    "- process datasets that exceed GPU and CPU memory without having to worry about scale\n",
    "- focus on what to do with the data and not how to do it by using abstraction at the operation level\n",
    "- prepare datasets quickly and easily for experimentation so that more models can be trained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9721f21-2f11-440b-a9ea-00e2bc668734",
   "metadata": {},
   "source": [
    "**Learning Objectives**\n",
    "\n",
    "Our goal is to predict the next city to be visited in a session. Therefore, we reshape the data to organize it into 'sessions', in other words, we generate sequential features per session (per trip). Each session will be a full customer itinerary in chronological order. \n",
    "\n",
    "Below, we do following data operations with NVTabular:\n",
    "- Categorify categorical columns with `Categorify()` operator\n",
    "- Create temporal features with `LambdaOp`\n",
    "- Create a new continuous feature using `LamdaOp`\n",
    "- Groupby dataset with `Groupby` op\n",
    "- Transform continuous features with `LogOp` and `Normalize` operators\n",
    "- Truncate the sequences using `LambdaOp`\n",
    "- Export the preprocessed datasets as parquet files and schema file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f53b8d-5d01-4bf7-a200-bc81719b5940",
   "metadata": {},
   "source": [
    "### 2.2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30dd1a8f-6de5-4453-b115-24007a4886bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 21:36:29.248378: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import glob\n",
    "import cudf \n",
    "import gc\n",
    "import nvtabular as nvt\n",
    "from nvtabular.ops import *\n",
    "\n",
    "from merlin.schema.tags import Tags\n",
    "from merlin.io.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b62473-f8d1-4997-96da-8d4b9e804615",
   "metadata": {},
   "source": [
    "Define the raw dataset path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb920d50-dc3a-43fd-96ab-c8066cfa4fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = os.environ.get(\n",
    "    \"DATA_FOLDER\", \n",
    "    '/workspace/data/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b8f9ae-e213-45ed-b438-07b5766973cf",
   "metadata": {},
   "source": [
    "Read in the train and valid parquet files as cudf data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a753d8f6-ac30-4a85-b053-2254e22c1340",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=cudf.read_parquet(os.path.join(DATA_FOLDER, \"train.parquet\"))\n",
    "valid=cudf.read_parquet(os.path.join(DATA_FOLDER, \"valid.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b777af16-c2ea-4891-9c7e-044b91abf43f",
   "metadata": {},
   "source": [
    "Let's look at the raw input features and see what kind of features we can use and create from these features. The goal of feature engineering is simply to adapt the data better to the task (problem) we tackle with. Feature engineering is primarily done to improve the model's predictive power. We can start by selecting the features that are more relevant in predicting the target. From there, we can also engineer new features, that might have better correlation with the target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f67aff35-8334-4b22-bd7b-d747c5504e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id    checkin   checkout  city_id device_class  affiliate_id  \\\n",
      "0  2000964 2015-12-31 2016-01-01    63341       mobile          8151   \n",
      "1  2595109 2015-12-31 2016-01-01    27404       mobile           359   \n",
      "2   727105 2015-12-31 2016-01-01    18820       mobile           359   \n",
      "3  1032571 2016-01-01 2016-01-02    21996       mobile          9924   \n",
      "4   110418 2016-01-01 2016-01-02     3763      desktop          9924   \n",
      "\n",
      "         booker_country hotel_country   utrip_id  \n",
      "0  The Devilfire Empire  Cobra Island  2000964_1  \n",
      "1  The Devilfire Empire  Cobra Island  2595109_1  \n",
      "2  The Devilfire Empire  Cobra Island   727105_1  \n",
      "3  The Devilfire Empire  Cobra Island  1032571_1  \n",
      "4  The Devilfire Empire  Glubbdubdrib   110418_1  \n"
     ]
    }
   ],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0694d495-dd1c-4471-99f8-2f8dd8bf7b66",
   "metadata": {},
   "source": [
    " `city_id` column is the main feature for us to use. By using user's travel history, our goal is to predict the next one that a traveler can visit. Note that we can create a model only using sequence of city_id as an input feature. However, we can also explore what other features we can feed to our model, so that we can improve model's accuracy.\n",
    "\n",
    "Our dataset has timestamp (checkin and checkout) columns. We can create temporal features such as the <i>weekday</i>, <i>month</i> or another temporal feature from `checkin` or `checkout` columns. These features can give information about users' temporal behaviours, and, tells us which cities are more preferred when.\n",
    "\n",
    "The location of the booker and the hotel's location be two important features as well to predict what the next city a traveler can visit.\n",
    "\n",
    "Similarly we can think about creating other features like `length of a stay` for every stay or `number of cities visited` in a given user trip."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aa44b7-26e7-4e4b-b6df-690869fc09cc",
   "metadata": {},
   "source": [
    "Create temporal features and categorify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83df7977-4ad0-4f56-b454-738448d1899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_checkin = (\n",
    "    [\"checkin\"]\n",
    "    >> LambdaOp(lambda col: col.dt.weekday)\n",
    "    >> Categorify()\n",
    "    >> Rename(name=\"weekday_checkin\")\n",
    ")\n",
    "\n",
    "weekday_checkout = (\n",
    "    [\"checkout\"]\n",
    "    >> LambdaOp(lambda col: col.dt.weekday)\n",
    "    >> Categorify()\n",
    "    >> Rename(name=\"weekday_checkout\")\n",
    ")\n",
    "\n",
    "month_checkin = (\n",
    "    [\"checkin\"]\n",
    "    >> LambdaOp(lambda col: col.dt.month)\n",
    "    >> Categorify() \n",
    "    >> Rename(name=\"month_checkin\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2886ae4-6602-41e6-a41e-ef7551b02b4c",
   "metadata": {},
   "source": [
    "Create a new feature from length of stay of each stay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc7fb0b0-66ab-4730-bff7-8788703b15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_stay(col, gdf):\n",
    "    stay_length = (gdf['checkout'] - col).dt.days\n",
    "    return stay_length\n",
    "\n",
    "    \n",
    "length_of_stay = (['checkin'] \n",
    "                  >> LambdaOp(length_stay, dependency=['checkout']) \n",
    "                  >> LogOp() \n",
    "                  >> Normalize()\n",
    "                  >> AddTags([Tags.SEQUENCE])\n",
    "                  >> Rename(name=\"length_of_stay\")\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bbaf01-63ed-4380-ba0c-f8cf943ea9ce",
   "metadata": {},
   "source": [
    "Let's group interactions (each user travel) into sessions. Currently, every row is a traveled city in the dataset. Our goal is to predict (and recommend) the final city (city_id) of each trip (utrip_id). Therefore, we groupby the dataset by `utrip_id` to have one row for each prediction. Each row will have a sequence of encoded city ids which a user visited. The NVTabular `GroupBy` op enables the transformation by sorting the columns according to `checkin` date, and then aggregating the interactions per `utrip_id` based on the aggregation method we define below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba429715-9a82-4289-af47-d62b681655fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_cat = ['city_id'] >> Categorify() \n",
    "\n",
    "# jointly encode\n",
    "location = [['booker_country', 'hotel_country']] >> Categorify()\n",
    "\n",
    "# filter out the rows where the city_id is 0. \n",
    "# This applies on validation set since the OOV cities are mapped to 0 in validation set.\n",
    "filtered_feats= (\n",
    "    city_cat + ['utrip_id', 'checkin'] + location + weekday_checkin + weekday_checkout + month_checkin + length_of_stay \n",
    "    >> Filter(f=lambda df: df[\"city_id\"]!=0)\n",
    ")\n",
    "\n",
    "groupby_features = (filtered_feats\n",
    "                    >> Groupby(\n",
    "                        groupby_cols=['utrip_id'],\n",
    "                        aggs={\n",
    "                            'city_id': ['list', 'count', 'last'],\n",
    "                            'booker_country': ['list'],\n",
    "                            'hotel_country': ['list'],\n",
    "                            'weekday_checkin': ['list'],\n",
    "                            'weekday_checkout': ['list'],\n",
    "                            \"month_checkin\": ['list'],\n",
    "                            \"length_of_stay\": ['list'],\n",
    "                        },\n",
    "                        sort_cols=[\"checkin\"]\n",
    "                    )\n",
    "                   )\n",
    "\n",
    "groupby_features_city = (groupby_features['city_id_list'] \n",
    "                         >> AddTags([Tags.ITEM, Tags.ITEM_ID, Tags.SEQUENCE])\n",
    "                        )\n",
    "\n",
    "groupby_features_country = (\n",
    "    groupby_features['booker_country_list', 'hotel_country_list']\n",
    "    >> AddTags([Tags.SEQUENCE])\n",
    ")\n",
    "\n",
    "groupby_features_time = (\n",
    "    groupby_features['weekday_checkin_list', 'weekday_checkout_list', 'month_checkin_list']\n",
    "    >> AddTags([Tags.SEQUENCE])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c052b5-3c66-421f-acb3-600574587c4c",
   "metadata": {},
   "source": [
    "We truncate the sequence features in length via `sessions_max_length` param, which is set as 10 in this example. In addition, we filter out the sessions that have less than 2 travels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b58131d-8c85-4fd5-8bca-6b72a649d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "SESSIONS_MAX_LENGTH= 10\n",
    "truncated_features = (groupby_features_city + groupby_features_country + groupby_features_time + groupby_features['length_of_stay_list']\n",
    "                      >> ListSlice(-SESSIONS_MAX_LENGTH) \n",
    "                     )\n",
    "\n",
    "# Filter out sessions with less than 2 interactions \n",
    "MINIMUM_SESSION_LENGTH = 2\n",
    "filtered_sessions = (groupby_features['utrip_id',  'city_id_count'] + truncated_features \n",
    "                     >> Filter(f=lambda df: df[\"city_id_count\"] >= MINIMUM_SESSION_LENGTH)\n",
    "                    )\n",
    "\n",
    "num_city_visited = (filtered_sessions['city_id_count']\n",
    "               >> LogOp() \n",
    "               >> Normalize()\n",
    "               >> Rename(name=\"num_city_visited\")\n",
    "               >> AddTags([Tags.CONTEXT,Tags.CONTINUOUS])\n",
    "              )\n",
    "\n",
    "list_feats = ['city_id_list', 'booker_country_list', 'hotel_country_list', 'weekday_checkin_list', 'weekday_checkout_list', 'month_checkin_list', 'length_of_stay_list']\n",
    "outputs = filtered_sessions[list_feats, 'utrip_id'] + num_city_visited "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1061ad46-1134-439b-a220-faa0bb6c2caf",
   "metadata": {},
   "source": [
    "Initialize the NVTabular dataset object and workflow graph. When we initialize a Workflow with our pipeline, workflow organizes the input and output columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "537b46af-201d-4e3b-843e-ef7c1d1c5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = nvt.Workflow(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c858242-0c58-465b-b099-66ba5bfaa645",
   "metadata": {},
   "source": [
    "Create NVTabular Dataset objects using our raw datasets. Then, we calculate statistics for this workflow on the input dataset, i.e. on our training set, using the `workflow.fit()` method so that our Workflow can use these stats to transform any given input. Note that when we export files to disk, we also export a `schema.pbtxt` file that we will use during modeling step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a557bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train)\n",
    "valid_dataset = Dataset(valid)\n",
    "\n",
    "# fit data\n",
    "workflow.fit(train_dataset)\n",
    "\n",
    "# transform train set and save data to disk\n",
    "workflow.transform(train_dataset).to_parquet(os.path.join(DATA_FOLDER, \"train/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652658eb-6f29-4d49-bf6a-4e6ba03371b4",
   "metadata": {},
   "source": [
    "Now we can transform our validation set and export transformed dataset to disk as a parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26aa249e-a0fc-4bf4-bcff-622531f3a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.transform(valid_dataset).to_parquet(os.path.join(DATA_FOLDER, \"valid/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0001807-e517-4d4b-a48c-8eb41bdf39e7",
   "metadata": {},
   "source": [
    "We can check out the output schema of the workflow. Take a look at what meta data output schema stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f91cad0-831d-4d5f-a18c-1c82d48b4a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.start_index</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.value_count.min</th>\n",
       "      <th>properties.value_count.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>utrip_id</td>\n",
       "      <td>()</td>\n",
       "      <td>DType(name='object', element_type=&lt;ElementType...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>city_id_list</td>\n",
       "      <td>(Tags.LIST, Tags.SEQUENCE, Tags.CATEGORICAL, T...</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.city_id.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39664.0</td>\n",
       "      <td>city_id</td>\n",
       "      <td>39665.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>booker_country_list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST, Tags.SEQUENCE)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.booker_country_hotel_coun...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>booker_country_hotel_country</td>\n",
       "      <td>196.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hotel_country_list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST, Tags.SEQUENCE)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.booker_country_hotel_coun...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>booker_country_hotel_country</td>\n",
       "      <td>196.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weekday_checkin_list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST, Tags.SEQUENCE)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.checkin.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>checkin</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weekday_checkout_list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST, Tags.SEQUENCE)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.checkout.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>checkout</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>month_checkin_list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST, Tags.SEQUENCE)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.checkin.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>checkin</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>length_of_stay_list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST, Tags.SEQUENCE)</td>\n",
       "      <td>DType(name='float64', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num_city_visited</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.CONTEXT)</td>\n",
       "      <td>DType(name='float64', element_type=&lt;ElementTyp...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.city_id.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39664.0</td>\n",
       "      <td>city_id</td>\n",
       "      <td>39665.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'utrip_id', 'tags': set(), 'properties': {}, 'dtype': DType(name='object', element_type=<ElementType.Object: 'object'>, element_size=None, element_unit=None, signed=None, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'city_id_list', 'tags': {<Tags.LIST: 'list'>, <Tags.SEQUENCE: 'sequence'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.ID: 'id'>, <Tags.ITEM: 'item'>, <Tags.ITEM_ID: 'item_id'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.city_id.parquet', 'domain': {'min': 0, 'max': 39664, 'name': 'city_id'}, 'embedding_sizes': {'cardinality': 39665, 'dimension': 512}, 'value_count': {'min': 0, 'max': 10}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'booker_country_list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>, <Tags.SEQUENCE: 'sequence'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.booker_country_hotel_country.parquet', 'domain': {'min': 0, 'max': 195, 'name': 'booker_country_hotel_country'}, 'embedding_sizes': {'cardinality': 196, 'dimension': 31}, 'value_count': {'min': 0, 'max': 10}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'hotel_country_list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>, <Tags.SEQUENCE: 'sequence'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.booker_country_hotel_country.parquet', 'domain': {'min': 0, 'max': 195, 'name': 'booker_country_hotel_country'}, 'embedding_sizes': {'cardinality': 196, 'dimension': 31}, 'value_count': {'min': 0, 'max': 10}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'weekday_checkin_list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>, <Tags.SEQUENCE: 'sequence'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.checkin.parquet', 'domain': {'min': 0, 'max': 7, 'name': 'checkin'}, 'embedding_sizes': {'cardinality': 8, 'dimension': 16}, 'value_count': {'min': 0, 'max': 10}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'weekday_checkout_list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>, <Tags.SEQUENCE: 'sequence'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.checkout.parquet', 'domain': {'min': 0, 'max': 7, 'name': 'checkout'}, 'embedding_sizes': {'cardinality': 8, 'dimension': 16}, 'value_count': {'min': 0, 'max': 10}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'month_checkin_list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>, <Tags.SEQUENCE: 'sequence'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.checkin.parquet', 'domain': {'min': 0, 'max': 7, 'name': 'checkin'}, 'embedding_sizes': {'cardinality': 8, 'dimension': 16}, 'value_count': {'min': 0, 'max': 10}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'length_of_stay_list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>, <Tags.SEQUENCE: 'sequence'>}, 'properties': {'value_count': {'min': 0, 'max': 10}}, 'dtype': DType(name='float64', element_type=<ElementType.Float: 'float'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'num_city_visited', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.CONTEXT: 'context'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.city_id.parquet', 'domain': {'min': 0, 'max': 39664, 'name': 'city_id'}, 'embedding_sizes': {'cardinality': 39665, 'dimension': 512}}, 'dtype': DType(name='float64', element_type=<ElementType.Float: 'float'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.output_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1ec707-90f3-4fa4-b4b1-b4f3d9e94d0a",
   "metadata": {},
   "source": [
    "Let's print the head of our preprocessed train dataset. You can notice that now each example (row) is a session and the sequential features with respect to user interactions were converted to lists with matching length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e461d0ea-f1fd-4913-8d5b-44b1085b1175",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=cudf.read_parquet(os.path.join(DATA_FOLDER, 'train', 'part_0.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5b08b19-68b7-46a6-905d-8dc3146d0597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    utrip_id             city_id_list booker_country_list hotel_country_list  \\\n",
      "0  1000027_1  [8264, 154, 2312, 2027]        [2, 2, 2, 2]       [1, 1, 1, 1]   \n",
      "1  1000033_1  [62, 1258, 90, 629, 62]     [1, 1, 1, 1, 1]    [4, 4, 4, 4, 4]   \n",
      "\n",
      "  weekday_checkin_list weekday_checkout_list month_checkin_list  \\\n",
      "0         [5, 7, 4, 3]          [7, 4, 2, 7]       [0, 0, 0, 0]   \n",
      "1      [5, 1, 4, 3, 5]       [6, 4, 2, 5, 4]    [6, 6, 6, 6, 6]   \n",
      "\n",
      "                                 length_of_stay_list  num_city_visited  \n",
      "0  [-0.736162543296814, 0.4681011438369751, 0.468...         -0.798553  \n",
      "1  [0.4681011438369751, -0.736162543296814, 0.468...         -0.085908  \n"
     ]
    }
   ],
   "source": [
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f864bfc-b5bf-42a7-a781-c93fd0d551d4",
   "metadata": {},
   "source": [
    "Save the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5af492ef-54ce-410c-9066-6532d76df1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.save(os.path.join(DATA_FOLDER, \"workflow_etl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8be18187-f813-4b37-98c7-6728578ea10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1017"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train, valid, train_dataset, valid_dataset, df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8f0b8a-2489-465d-9a10-e69b78b4444e",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a1a18-7169-43ec-81c9-974845134721",
   "metadata": {},
   "source": [
    "In this lab, we learned how to transform our dataset and create sequential features to train and evaluate a session-based recommendation model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4507c0ef-d58e-44ff-a1f2-7d0c1670ff5a",
   "metadata": {},
   "source": [
    "Please execute the cell below to shut down the kernel before moving on to the next notebook `03-Next-item-prediction-with-MLP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35120a9a-2189-4a6a-ac6e-d7ddfca3956e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
