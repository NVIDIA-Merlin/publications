{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cd5fcdb-f0af-48db-8bbe-2668df514d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ================================\n",
    "\n",
    "# Each user is responsible for checking the content of datasets and the\n",
    "# applicable licenses and determining if suitable for the intended use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e770427-d8c4-4b9e-8596-d89222c5f0e5",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Feature Engineering with MERLIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e33099a-adb8-4d50-b00a-fa83584f04fb",
   "metadata": {},
   "source": [
    "### 2.1. Feature Engineering on GPU with NVTabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf0d169-bf9f-48f3-b8be-230bb68fcf6e",
   "metadata": {},
   "source": [
    "Merlin [NVTabular](https://github.com/NVIDIA-Merlin/NVTabular) is a feature engineering and preprocessing library for tabular data that is designed to easily manipulate terabyte scale datasets and train deep learning (DL) based recommender systems. It provides high-level abstraction to simplify code and accelerates computation on the GPU using the RAPIDS Dask-cuDF library. If you want to learn more about NVTabular, we recommend the examples in the NVTabular GitHub [repository](https://github.com/NVIDIA-Merlin/NVTabular/tree/main/examples).\n",
    "\n",
    "- process datasets that exceed GPU and CPU memory without having to worry about scale\n",
    "- focus on what to do with the data and not how to do it by using abstraction at the operation level\n",
    "- prepare datasets quickly and easily for experimentation so that more models can be trained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9721f21-2f11-440b-a9ea-00e2bc668734",
   "metadata": {},
   "source": [
    "**Learning Objectives**\n",
    "\n",
    "Our goal is to predict the next city to be visited in a session. Therefore, we reshape the data to organize it into 'sessions', in other words, we generate sequential features per session (per trip). Each session will be a full customer itinerary in chronological order. \n",
    "\n",
    "Below, we do following data operations with NVTabular:\n",
    "- Categorify categorical columns with `Categorify()` operator\n",
    "- Create temporal features with `LambdaOp`\n",
    "- Create a new continuous feature using `LamdaOp`\n",
    "- Groupby dataset with `Groupby` op\n",
    "- Transform continuous features with `LogOp` and `Normalize` operators\n",
    "- Truncate the sequences using `LambdaOp`\n",
    "- Export the preprocessed datasets as parquet files and schema file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f53b8d-5d01-4bf7-a200-bc81719b5940",
   "metadata": {},
   "source": [
    "### 2.2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30dd1a8f-6de5-4453-b115-24007a4886bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 19:00:43.882343: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import glob\n",
    "import cudf \n",
    "import gc\n",
    "import nvtabular as nvt\n",
    "from nvtabular.ops import *\n",
    "\n",
    "from merlin.schema.tags import Tags\n",
    "from merlin.io.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b62473-f8d1-4997-96da-8d4b9e804615",
   "metadata": {},
   "source": [
    "Define the raw dataset path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb920d50-dc3a-43fd-96ab-c8066cfa4fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = os.environ.get(\n",
    "    \"DATA_FOLDER\", \n",
    "    '/workspace/data/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b8f9ae-e213-45ed-b438-07b5766973cf",
   "metadata": {},
   "source": [
    "Read in the train and valid parquet files as cudf data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a753d8f6-ac30-4a85-b053-2254e22c1340",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=cudf.read_parquet(os.path.join(DATA_FOLDER, \"train.parquet\"))\n",
    "valid=cudf.read_parquet(os.path.join(DATA_FOLDER, \"valid.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aa44b7-26e7-4e4b-b6df-690869fc09cc",
   "metadata": {},
   "source": [
    "Create temporal features and categorify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83df7977-4ad0-4f56-b454-738448d1899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_checkin = (\n",
    "    [\"checkin\"]\n",
    "    >> LambdaOp(lambda col: col.dt.weekday)\n",
    "    >> Categorify()\n",
    "    >> Rename(name=\"weekday_checkin\")\n",
    ")\n",
    "\n",
    "weekday_checkout = (\n",
    "    [\"checkout\"]\n",
    "    >> LambdaOp(lambda col: col.dt.weekday)\n",
    "    >> Categorify()\n",
    "    >> Rename(name=\"weekday_checkout\")\n",
    ")\n",
    "\n",
    "month_checkin = (\n",
    "    [\"checkin\"]\n",
    "    >> LambdaOp(lambda col: col.dt.month)\n",
    "    >> Categorify() \n",
    "    >> Rename(name=\"month_checkin\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2886ae4-6602-41e6-a41e-ef7551b02b4c",
   "metadata": {},
   "source": [
    "Create a new feature from length of stay of each stay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc7fb0b0-66ab-4730-bff7-8788703b15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_stay(col, gdf):\n",
    "    stay_length = (gdf['checkout'] - col).dt.days\n",
    "    return stay_length\n",
    "\n",
    "    \n",
    "length_of_stay = (['checkin'] \n",
    "                  >> LambdaOp(length_stay, dependency=['checkout']) \n",
    "                  >> LogOp() \n",
    "                  >> Normalize()\n",
    "                  >> AddTags([Tags.SEQUENCE])\n",
    "                  >> Rename(name=\"length_of_stay\")\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bbaf01-63ed-4380-ba0c-f8cf943ea9ce",
   "metadata": {},
   "source": [
    "Let's group interactions (each user travel) into sessions. Currently, every row is a traveled city in the dataset. Our goal is to predict (and recommend) the final city (city_id) of each trip (utrip_id). Therefore, we groupby the dataset by `utrip_id` to have one row for each prediction.\n",
    "\n",
    "Each row will have a sequence of encoded city ids with which a user visited. The NVTabular GroupBy op enables the transformation by sorting the columns according to `checkin` date, and then aggregating the interactions per utrip_id based on the aggregation method we define."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba429715-9a82-4289-af47-d62b681655fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_cat = ['city_id'] >> Categorify() \n",
    "\n",
    "# filter out the rows where the city_id is 0. \n",
    "# This applies on validation set since the OOV cities are mapped to 0 in validation set.\n",
    "filtered_feats= (\n",
    "    city_cat + ['booker_country', 'utrip_id', 'hotel_country', 'checkin'] + weekday_checkin + weekday_checkout + month_checkin + length_of_stay \n",
    "    >> Filter(f=lambda df: df[\"city_id\"]!=0)\n",
    ")\n",
    "\n",
    "groupby_features = (filtered_feats\n",
    "                    >> Groupby(\n",
    "                        groupby_cols=['utrip_id'],\n",
    "                        aggs={\n",
    "                            'city_id': ['list', 'count', 'last'],\n",
    "                            'booker_country': ['list'],\n",
    "                            'hotel_country': ['list'],\n",
    "                            'weekday_checkin': ['list'],\n",
    "                            'weekday_checkout': ['list'],\n",
    "                            \"month_checkin\": ['list'],\n",
    "                            \"length_of_stay\": ['list'],\n",
    "                        },\n",
    "                        sort_cols=[\"checkin\"]\n",
    "                    )\n",
    "                   )\n",
    "\n",
    "groupby_features_city = (groupby_features['city_id_list'] \n",
    "                         >> AddTags([Tags.ITEM, Tags.ITEM_ID, Tags.SEQUENCE])\n",
    "                        )\n",
    "\n",
    "# jointly encode\n",
    "groupby_features_country = (\n",
    "    groupby_features[['booker_country_list', 'hotel_country_list']]\n",
    "    >> Categorify() >> AddTags([Tags.SEQUENCE])\n",
    ")\n",
    "\n",
    "groupby_features_time = (\n",
    "    groupby_features['weekday_checkin_list', 'weekday_checkout_list', 'month_checkin_list']\n",
    "    >> AddTags([Tags.SEQUENCE])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c052b5-3c66-421f-acb3-600574587c4c",
   "metadata": {},
   "source": [
    "We truncate the sequence features in length via `sessions_max_length` param, which is set as 10 in this example. In addition, we filter out the sessions that have less than 2 travels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b58131d-8c85-4fd5-8bca-6b72a649d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "SESSIONS_MAX_LENGTH= 10\n",
    "truncated_features = (groupby_features_city + groupby_features_country + groupby_features_time + groupby_features['length_of_stay_list']\n",
    "                      >> ListSlice(-SESSIONS_MAX_LENGTH) \n",
    "                     )\n",
    "\n",
    "# Filter out sessions with less than 2 interactions \n",
    "MINIMUM_SESSION_LENGTH = 2\n",
    "filtered_sessions = (groupby_features['utrip_id',  'city_id_count'] + truncated_features \n",
    "                     >> Filter(f=lambda df: df[\"city_id_count\"] >= MINIMUM_SESSION_LENGTH)\n",
    "                    )\n",
    "\n",
    "num_city_visited = (filtered_sessions['city_id_count']\n",
    "               >> LogOp() \n",
    "               >> Normalize()\n",
    "               >> Rename(name=\"num_city_visited\")\n",
    "               >> AddTags([Tags.CONTEXT,Tags.CONTINUOUS])\n",
    "              )\n",
    "\n",
    "list_feats = ['city_id_list', 'booker_country_list', 'hotel_country_list', 'weekday_checkin_list', 'weekday_checkout_list', 'month_checkin_list', 'length_of_stay_list']\n",
    "outputs = filtered_sessions[list_feats, 'utrip_id'] + num_city_visited "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1061ad46-1134-439b-a220-faa0bb6c2caf",
   "metadata": {},
   "source": [
    "Initialize the NVTabular dataset object and workflow graph. When we initialize a Workflow with our pipeline, workflow organizes the input and output columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "537b46af-201d-4e3b-843e-ef7c1d1c5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = nvt.Workflow(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c858242-0c58-465b-b099-66ba5bfaa645",
   "metadata": {},
   "source": [
    "Create NVTabular Dataset objects using our raw datasets. Then, we calculate statistics for this workflow on the input dataset, i.e. on our training set, using the `workflow.fit()` method so that our Workflow can use these stats to transform any given input. Note that when we export files to disk, we also export a `schema.pbtxt` file that we will use during modeling step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a557bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train)\n",
    "valid_dataset = Dataset(valid)\n",
    "\n",
    "# fit data\n",
    "workflow.fit(train_dataset)\n",
    "\n",
    "# transform train set and save data to disk\n",
    "workflow.transform(train_dataset).to_parquet(os.path.join(DATA_FOLDER, \"train/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652658eb-6f29-4d49-bf6a-4e6ba03371b4",
   "metadata": {},
   "source": [
    "Now we can transform our validation set and export transformed dataset to disk as a parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26aa249e-a0fc-4bf4-bcff-622531f3a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.transform(valid_dataset).to_parquet(os.path.join(DATA_FOLDER, \"valid/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0001807-e517-4d4b-a48c-8eb41bdf39e7",
   "metadata": {},
   "source": [
    "We can check out the output schema of the workflow. Take a look at what meta data output schema stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f91cad0-831d-4d5f-a18c-1c82d48b4a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.start_index</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.value_count.min</th>\n",
       "      <th>properties.value_count.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>utrip_id</td>\n",
       "      <td>()</td>\n",
       "      <td>DType(name='object', element_type=&lt;ElementType...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>city_id_list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.ITEM, Tags.ID, Tags.SE...</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.city_id.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39664.0</td>\n",
       "      <td>city_id</td>\n",
       "      <td>39665.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>booker_country_list</td>\n",
       "      <td>(Tags.SEQUENCE, Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.booker_country_list.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>booker_country_list</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hotel_country_list</td>\n",
       "      <td>(Tags.SEQUENCE, Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.hotel_country_list.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>hotel_country_list</td>\n",
       "      <td>196.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weekday_checkin_list</td>\n",
       "      <td>(Tags.SEQUENCE, Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.checkin.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>checkin</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weekday_checkout_list</td>\n",
       "      <td>(Tags.SEQUENCE, Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.checkout.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>checkout</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>month_checkin_list</td>\n",
       "      <td>(Tags.SEQUENCE, Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.checkin.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>checkin</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>length_of_stay_list</td>\n",
       "      <td>(Tags.SEQUENCE, Tags.LIST, Tags.CONTINUOUS)</td>\n",
       "      <td>DType(name='float64', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num_city_visited</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.CONTEXT)</td>\n",
       "      <td>DType(name='float64', element_type=&lt;ElementTyp...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.city_id.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39664.0</td>\n",
       "      <td>city_id</td>\n",
       "      <td>39665.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'utrip_id', 'tags': set(), 'properties': {}, 'dtype': DType(name='object', element_type=<ElementType.Object: 'object'>, element_size=None, element_unit=None, signed=None, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'city_id_list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.ITEM: 'item'>, <Tags.ID: 'id'>, <Tags.SEQUENCE: 'sequence'>, <Tags.ITEM_ID: 'item_id'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.city_id.parquet', 'domain': {'min': 0, 'max': 39664, 'name': 'city_id'}, 'embedding_sizes': {'cardinality': 39665, 'dimension': 512}, 'value_count': {'min': 0, 'max': 10}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'booker_country_list', 'tags': {<Tags.SEQUENCE: 'sequence'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.booker_country_list.parquet', 'domain': {'min': 0, 'max': 5, 'name': 'booker_country_list'}, 'embedding_sizes': {'cardinality': 6, 'dimension': 16}, 'value_count': {'min': 0, 'max': 10}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'hotel_country_list', 'tags': {<Tags.SEQUENCE: 'sequence'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.hotel_country_list.parquet', 'domain': {'min': 0, 'max': 195, 'name': 'hotel_country_list'}, 'embedding_sizes': {'cardinality': 196, 'dimension': 31}, 'value_count': {'min': 0, 'max': 10}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'weekday_checkin_list', 'tags': {<Tags.SEQUENCE: 'sequence'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.checkin.parquet', 'domain': {'min': 0, 'max': 12, 'name': 'checkin'}, 'embedding_sizes': {'cardinality': 13, 'dimension': 16}, 'value_count': {'min': 0, 'max': 10}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'weekday_checkout_list', 'tags': {<Tags.SEQUENCE: 'sequence'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.checkout.parquet', 'domain': {'min': 0, 'max': 7, 'name': 'checkout'}, 'embedding_sizes': {'cardinality': 8, 'dimension': 16}, 'value_count': {'min': 0, 'max': 10}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'month_checkin_list', 'tags': {<Tags.SEQUENCE: 'sequence'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.checkin.parquet', 'domain': {'min': 0, 'max': 12, 'name': 'checkin'}, 'embedding_sizes': {'cardinality': 13, 'dimension': 16}, 'value_count': {'min': 0, 'max': 10}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'length_of_stay_list', 'tags': {<Tags.SEQUENCE: 'sequence'>, <Tags.LIST: 'list'>, <Tags.CONTINUOUS: 'continuous'>}, 'properties': {'value_count': {'min': 0, 'max': 10}}, 'dtype': DType(name='float64', element_type=<ElementType.Float: 'float'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=10)))), 'is_list': True, 'is_ragged': True}, {'name': 'num_city_visited', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.CONTEXT: 'context'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.city_id.parquet', 'domain': {'min': 0, 'max': 39664, 'name': 'city_id'}, 'embedding_sizes': {'cardinality': 39665, 'dimension': 512}}, 'dtype': DType(name='float64', element_type=<ElementType.Float: 'float'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.output_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1ec707-90f3-4fa4-b4b1-b4f3d9e94d0a",
   "metadata": {},
   "source": [
    "Let's print the head of our preprocessed train dataset. You can notice that now each example (row) is a session and the sequential features with respect to user interactions were converted to lists with matching length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e461d0ea-f1fd-4913-8d5b-44b1085b1175",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=cudf.read_parquet('/workspace/data/train/part_0.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5b08b19-68b7-46a6-905d-8dc3146d0597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    utrip_id             city_id_list booker_country_list hotel_country_list  \\\n",
      "0  1000027_1  [8264, 154, 2312, 2027]        [3, 3, 3, 3]       [3, 3, 3, 3]   \n",
      "1  1000033_1  [62, 1258, 90, 629, 62]     [1, 1, 1, 1, 1]    [1, 1, 1, 1, 1]   \n",
      "\n",
      "  weekday_checkin_list weekday_checkout_list month_checkin_list  \\\n",
      "0       [5, 6, 12, 10]          [7, 4, 2, 7]       [1, 1, 1, 1]   \n",
      "1    [5, 0, 12, 10, 5]       [6, 4, 2, 5, 4]    [7, 7, 7, 7, 7]   \n",
      "\n",
      "                                 length_of_stay_list  num_city_visited  \n",
      "0  [-0.736162543296814, 0.4681011438369751, 0.468...         -0.798553  \n",
      "1  [0.4681011438369751, -0.736162543296814, 0.468...         -0.085908  \n"
     ]
    }
   ],
   "source": [
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f864bfc-b5bf-42a7-a781-c93fd0d551d4",
   "metadata": {},
   "source": [
    "Save the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5af492ef-54ce-410c-9066-6532d76df1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.save(os.path.join(DATA_FOLDER, \"workflow_etl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8be18187-f813-4b37-98c7-6728578ea10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1490"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train, valid, train_dataset, valid_dataset, df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8f0b8a-2489-465d-9a10-e69b78b4444e",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a1a18-7169-43ec-81c9-974845134721",
   "metadata": {},
   "source": [
    "In this lab, we learned how to transform our dataset and create sequential features to train and evaluate a session-based recommendation model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4507c0ef-d58e-44ff-a1f2-7d0c1670ff5a",
   "metadata": {},
   "source": [
    "Please execute the cell below to shut down the kernel before moving on to the next notebook `03-Next-item-prediction-with-MLP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35120a9a-2189-4a6a-ac6e-d7ddfca3956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
