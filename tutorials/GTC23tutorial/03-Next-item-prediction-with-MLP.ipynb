{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96de18a-caae-4029-bb74-18b6751c123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ================================\n",
    "\n",
    "# Each user is responsible for checking the content of datasets and the\n",
    "# applicable licenses and determining if suitable for the intended use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcf73f0-556c-4e1e-8bfa-2dd90cc0e513",
   "metadata": {},
   "source": [
    "## 3. Session-based Recommendations with MERLIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f1bdf4-79be-4953-a8b5-c44c92f6fc7a",
   "metadata": {},
   "source": [
    "Session-based recommendation, a sub-area of sequential recommendation, has been an important task in online services like e-commerce and news portals, where most users either browse anonymously or may have very distinct interests for different sessions. Session-Based Recommender Systems (SBRS) have been proposed to model the sequence of interactions within the current user session, where a session is a short sequence of user interactions typically bounded by user inactivity. They have recently gained popularity due to their ability to capture short-term and contextual user preferences towards items.\n",
    "\n",
    "Many methods have been proposed to leverage the sequence of interactions that occur during a session, including session-based k-NN algorithms like V-SkNN [1] and neural approaches like GRU4Rec [2]. In addition, state of the art NLP approaches have inspired RecSys practitioners and researchers to leverage the self-attention mechanism and the Transformer-based architectures for sequential [3] and session-based recommendation [4, 5]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceae86e-ff2e-400c-8b4a-1793466fceb4",
   "metadata": {},
   "source": [
    "<img src=\"./images/sessionbased.png\" width=800 height=400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc1f387-cc58-4439-ae7a-454d56efd14f",
   "metadata": {},
   "source": [
    "In this tutorial, we introduce the Merlin Models an open-source library that is designed to provide standard models for recommender systems with an aim for high-quality implementations that range from classic machine learning models to highly-advanced deep learning models. With Merlin Models we import from the HF Transformers NLP library the transformer architectures and their configuration classes.\n",
    "\n",
    "In addition, Merlin Models provides additional blocks necessary for recommendation, e.g., input features normalization and aggregation, and heads for recommendation and sequence classification/prediction. We also extend their Trainer class to allow for the evaluation with RecSys metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a142324e-597c-4618-af81-65c97b2a4e00",
   "metadata": {},
   "source": [
    "### Merlin Models\n",
    "Merlin Models is a library to make it easy for users in industry or academia to train and deploy recommender models with best practices baked into the library. This will let users in industry easily train standard models against their own dataset, getting high performance GPU accelerated models into production. This will also let researchers to build custom models by incorporating standard components of deep learning recommender models, and then benchmark their new models on example offline datasets. \n",
    "\n",
    "Core features are:\n",
    "- Unified API enables users to create models in TensorFlow \n",
    "- Seamless integration with NVTabular for feature engineering and model serving\n",
    "- Flexible APIs targeted to both production and research\n",
    "- Many different recommender system architectures (tabular, two-tower, sequential) or tasks (binary, multi-class classification, multi-task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757dc39a-6d8f-4762-8921-0af91a973457",
   "metadata": {},
   "source": [
    "**Learning Objectives:**</br>\n",
    "\n",
    "In this lab, participants will learn:\n",
    "- building an MLP model architecture for next-item prediction task with multi-class classification objective\n",
    "- training and evaluating an MLP model using sequential categorical and continuous input features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e382d0f1-0e35-4b08-b810-967a2adb5088",
   "metadata": {},
   "source": [
    "### 3.1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f47581-aa15-4796-9648-f5f00713de6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 20:08:45.367666: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "2023-02-23 20:08:47.974018: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-23 20:08:49.565700: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-02-23 20:08:49.565799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1637] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16249 MB memory:  -> device: 0, name: Quadro GV100, pci bus id: 0000:2d:00.0, compute capability: 7.0\n",
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "import glob\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "from merlin.schema.tags import Tags\n",
    "from merlin.io.dataset import Dataset\n",
    "\n",
    "import merlin.models.tf as mm\n",
    "from merlin.models.tf.core.aggregation import SequenceAggregator\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428cf3a9-0e39-4e36-9bec-03e8ae3e0f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e482e548-6720-4a68-bfc9-013127bb2f68",
   "metadata": {},
   "source": [
    "Define data path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "286e75c1-dd7c-49af-b3bf-ecd9d402079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = os.environ.get(\n",
    "    \"DATA_FOLDER\", \n",
    "    '/workspace/data/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c27fc6d-cbcf-4d5f-bb09-23c70e496427",
   "metadata": {},
   "source": [
    "Read in train and validation sets as Merlin Dataset objects. Note that these datasets have schema associated to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb714228-92d5-4e6a-a8fc-b618727c1b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train = Dataset(os.path.join(DATA_FOLDER, \"train/*.parquet\"))\n",
    "valid = Dataset(os.path.join(DATA_FOLDER, \"valid/*.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07857906-2c81-4bbe-91be-a3ba201ab09a",
   "metadata": {},
   "source": [
    "Define target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0414de6b-e5b8-4d69-88e0-afd70b63d7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'city_id_list'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = train.schema.select_by_tag(Tags.SEQUENCE).column_names[0]\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f813f722-e3fd-4399-8f82-2d122e2f60e9",
   "metadata": {},
   "source": [
    "### 3.2. Next-item prediction with an MLP Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362a7985-e1bb-4309-b08e-88a2bd64e063",
   "metadata": {},
   "source": [
    "We train a Multi-Layer Perceptron model using sequential categorical and continuous features that we created in the previous notebook. We use the last item in the `city_id_list` column as target. We visualize the architecture in the figure below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6d52a0-b24e-4992-a4ba-db594bf3107d",
   "metadata": {},
   "source": [
    "<img src=\"./images/mlp.png\" width=600 height=200/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6443fc95-5c75-4ecc-89fd-8d427c794048",
   "metadata": {},
   "source": [
    "Let's start with defining our hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2d9d322-6348-4c78-af91-3aafd9a0211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = int(os.environ.get(\n",
    "    \"EPOCHS\", \n",
    "    '3'\n",
    "))\n",
    "\n",
    "dmodel = int(os.environ.get(\n",
    "    \"dmodel\", \n",
    "    '64'\n",
    "))\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5c56f2-6b2f-4c29-8283-d04c338b7580",
   "metadata": {},
   "source": [
    "#### 3.2.2. Define the Schema object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40991f3-e479-4ef0-8337-215b6a3caec4",
   "metadata": {},
   "source": [
    "Merlin Models can infer a neural network architecture from the dataset schema. Remember, we added tags to each feature in NVTabular workflow. Now you can see these tags in the `train.schema`. If you want to learn more, we recommend our [Dataset Schema Example](https://github.com/NVIDIA-Merlin/models/blob/main/examples/02-Merlin-Models-and-NVTabular-integration.ipynb).\n",
    "\n",
    "Below, we define the schema object by using `select_by_name` method. With this method we can select the input columns that we want to train our model with. In addition, one can use `select_by_tag` method and create subschemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8d297e5-855f-4cac-b4a4-771905ac942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.schema = train.schema.select_by_name(['city_id_list','booker_country_list', 'hotel_country_list',\n",
    "                                            'weekday_checkin_list','weekday_checkout_list',\n",
    "                                            'month_checkin_list', 'length_of_stay_list', 'num_city_visited']\n",
    "                                          )\n",
    "\n",
    "valid.schema = train.schema\n",
    "schema_model = train.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fef0c423-49c9-45ee-8d38-228d0376b556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.start_index</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "      <th>properties.value_count.min</th>\n",
       "      <th>properties.value_count.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>city_id_list</td>\n",
       "      <td>(Tags.LIST, Tags.ID, Tags.CATEGORICAL, Tags.SE...</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.city_id.parquet</td>\n",
       "      <td>39665.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39664.0</td>\n",
       "      <td>city_id</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>booker_country_list</td>\n",
       "      <td>(Tags.LIST, Tags.CATEGORICAL, Tags.SEQUENCE)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.booker_country_list.parquet</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>booker_country_list</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hotel_country_list</td>\n",
       "      <td>(Tags.LIST, Tags.CATEGORICAL, Tags.SEQUENCE)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.hotel_country_list.parquet</td>\n",
       "      <td>196.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>hotel_country_list</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weekday_checkin_list</td>\n",
       "      <td>(Tags.LIST, Tags.CATEGORICAL, Tags.SEQUENCE)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.checkin.parquet</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>checkin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weekday_checkout_list</td>\n",
       "      <td>(Tags.LIST, Tags.CATEGORICAL, Tags.SEQUENCE)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.checkout.parquet</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>checkout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>month_checkin_list</td>\n",
       "      <td>(Tags.LIST, Tags.CATEGORICAL, Tags.SEQUENCE)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.checkin.parquet</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>checkin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>length_of_stay_list</td>\n",
       "      <td>(Tags.LIST, Tags.CONTINUOUS, Tags.SEQUENCE)</td>\n",
       "      <td>DType(name='float64', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_city_visited</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.CONTEXT)</td>\n",
       "      <td>DType(name='float64', element_type=&lt;ElementTyp...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.city_id.parquet</td>\n",
       "      <td>39665.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39664.0</td>\n",
       "      <td>city_id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'city_id_list', 'tags': {<Tags.LIST: 'list'>, <Tags.ID: 'id'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.SEQUENCE: 'sequence'>, <Tags.ITEM: 'item'>, <Tags.ITEM_ID: 'item_id'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.city_id.parquet', 'embedding_sizes': {'cardinality': 39665.0, 'dimension': 512.0}, 'domain': {'min': 0, 'max': 39664, 'name': 'city_id'}, 'value_count': {'min': 0.0, 'max': 10.0}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0.0, max=None), Dimension(min=0.0, max=10.0)))), 'is_list': True, 'is_ragged': True}, {'name': 'booker_country_list', 'tags': {<Tags.LIST: 'list'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.SEQUENCE: 'sequence'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.booker_country_list.parquet', 'embedding_sizes': {'cardinality': 6.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 5, 'name': 'booker_country_list'}, 'value_count': {'min': 0.0, 'max': 10.0}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0.0, max=None), Dimension(min=0.0, max=10.0)))), 'is_list': True, 'is_ragged': True}, {'name': 'hotel_country_list', 'tags': {<Tags.LIST: 'list'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.SEQUENCE: 'sequence'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.hotel_country_list.parquet', 'embedding_sizes': {'cardinality': 196.0, 'dimension': 31.0}, 'domain': {'min': 0, 'max': 195, 'name': 'hotel_country_list'}, 'value_count': {'min': 0.0, 'max': 10.0}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0.0, max=None), Dimension(min=0.0, max=10.0)))), 'is_list': True, 'is_ragged': True}, {'name': 'weekday_checkin_list', 'tags': {<Tags.LIST: 'list'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.SEQUENCE: 'sequence'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.checkin.parquet', 'embedding_sizes': {'cardinality': 13.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 12, 'name': 'checkin'}, 'value_count': {'min': 0.0, 'max': 10.0}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0.0, max=None), Dimension(min=0.0, max=10.0)))), 'is_list': True, 'is_ragged': True}, {'name': 'weekday_checkout_list', 'tags': {<Tags.LIST: 'list'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.SEQUENCE: 'sequence'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.checkout.parquet', 'embedding_sizes': {'cardinality': 8.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 7, 'name': 'checkout'}, 'value_count': {'min': 0.0, 'max': 10.0}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0.0, max=None), Dimension(min=0.0, max=10.0)))), 'is_list': True, 'is_ragged': True}, {'name': 'month_checkin_list', 'tags': {<Tags.LIST: 'list'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.SEQUENCE: 'sequence'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.checkin.parquet', 'embedding_sizes': {'cardinality': 13.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 12, 'name': 'checkin'}, 'value_count': {'min': 0.0, 'max': 10.0}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0.0, max=None), Dimension(min=0.0, max=10.0)))), 'is_list': True, 'is_ragged': True}, {'name': 'length_of_stay_list', 'tags': {<Tags.LIST: 'list'>, <Tags.CONTINUOUS: 'continuous'>, <Tags.SEQUENCE: 'sequence'>}, 'properties': {'value_count': {'min': 0.0, 'max': 10.0}}, 'dtype': DType(name='float64', element_type=<ElementType.Float: 'float'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0.0, max=None), Dimension(min=0.0, max=10.0)))), 'is_list': True, 'is_ragged': True}, {'name': 'num_city_visited', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.CONTEXT: 'context'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.city_id.parquet', 'embedding_sizes': {'cardinality': 39665.0, 'dimension': 512.0}, 'domain': {'min': 0.0, 'max': 39664.0, 'name': 'city_id'}}, 'dtype': DType(name='float64', element_type=<ElementType.Float: 'float'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0.0, max=None),))), 'is_list': False, 'is_ragged': False}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e40833b-b6cf-4776-8bca-383913ccb7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['city_id_list',\n",
       " 'booker_country_list',\n",
       " 'hotel_country_list',\n",
       " 'weekday_checkin_list',\n",
       " 'weekday_checkout_list',\n",
       " 'month_checkin_list',\n",
       " 'length_of_stay_list',\n",
       " 'num_city_visited']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.schema.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311d2cbd-40a7-4afc-aba5-9e882c27bbf2",
   "metadata": {},
   "source": [
    "#### 3.2.3. Build the MLP architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c80765-6bf1-4ae6-b18a-c2b8a9f35ddd",
   "metadata": {},
   "source": [
    "We are starting with a simple model, an MLP model to predict the next city to visit. Our goal is to use a given sequence and predict where a user (traveler) will travel next. Since we are training an MLP model to predict the last item in the sequence as target, we are going to use [SequencePredictLast](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/transforms/sequence.py#L255) training approach below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08715cf2-af63-4a1c-9f5d-805a213c2513",
   "metadata": {},
   "source": [
    "We build a model with a 2-layer MLPBlock, input_block as the input layer  and prediction_task as the prediction head.  Let's create the `Input Block` which takes sequential features, concatenate them and return the sequence of interaction embeddings. \n",
    "\n",
    "- **InputBlockV2** is the input block for sequential features. Based on a `schema` object and options set by the user, it dynamically creates all the necessary layers (e.g. embedding layers) to encode, normalize, and aggregate categorical and continuous features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d1f95b-175e-429b-ad26-4aee98c55e91",
   "metadata": {},
   "source": [
    "Note that with `dim` arg, we can feed a fix dimension for all  categorical features, or a dictionary of the embedding dimensions if we want to set the embedding dimension different for each categorical feature. In this example, we set the embedding dimension as `16` for each categorical feature.\n",
    "\n",
    "We set `continuous` arg that lets us to apply aggregation on continuous list columns. Note that `length_of_stay_list` input feature is a list continuous column, and below we apply mean aggreation on the values of this column per input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "444916af-dd82-49cb-af92-3d7a39d1d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_block = mm.InputBlockV2(\n",
    "    schema_model,\n",
    "    categorical=mm.Embeddings(\n",
    "        schema_model.select_by_tag(Tags.CATEGORICAL), \n",
    "        sequence_combiner=\"mean\",\n",
    "        dim=16\n",
    "    ),\n",
    "    continuous=mm.Continuous(post=SequenceAggregator(\"mean\")),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b66e9c-0bbd-42fb-aa86-a740bb35f947",
   "metadata": {},
   "source": [
    "Let's check the output tensor dimension from input block. Let's define a batch and feed that to `input_block`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51cee3fd-01b0-48c9-9f0f-9b34935f41df",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = mm.sample_batch(train, batch_size=BATCH_SIZE, include_targets=False, to_ragged=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f6f749f-7329-4ebb-808a-6bc4cc015b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1024, 98])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_block(batch).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4f2412-d7de-4e61-9e46-697734584743",
   "metadata": {},
   "source": [
    "We obtain a 2-D sequence representation (batch_size, sum_of_emb_dim_of_features + 1-d of the continuous features). Note that total embedding dimension for categorical features is 96, and extra dimensions come from the continuous input features (`length_of_stay_list` and `num_city_visited`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f00dd04-98fb-42fb-a092-bf4b697e5ed0",
   "metadata": {},
   "source": [
    "Define an MLP block with two hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9347183c-7747-4bc1-b131-9a014cbc3b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_block = mm.MLPBlock(\n",
    "        [128, dmodel], \n",
    "        no_activation_last_layer=True, \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec8a65c-e3e7-4af1-861d-99f8f40b3447",
   "metadata": {},
   "source": [
    "Similarly we can check the output of the mlp_block. MLP block projects the output dimension as `dmodel` since we set the number of neurons in the second hidden layer as `64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01dfceeb-9d07-43b4-9871-32100e2ad81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1024, 64), dtype=float32, numpy=\n",
       "array([[ 0.06843954,  0.03452714,  0.00337486, ...,  0.10803191,\n",
       "        -0.0130931 ,  0.02420143],\n",
       "       [-0.01964401,  0.01131665, -0.01562893, ...,  0.0337671 ,\n",
       "        -0.01954725, -0.00809142],\n",
       "       [ 0.01400696, -0.00550668, -0.07824401, ...,  0.06993526,\n",
       "        -0.06954388,  0.00429055],\n",
       "       ...,\n",
       "       [-0.1097099 , -0.01124749, -0.03097691, ...,  0.23646343,\n",
       "        -0.05934976, -0.0206476 ],\n",
       "       [ 0.02554754,  0.00850445,  0.02615668, ...,  0.1427507 ,\n",
       "        -0.02937096,  0.03578164],\n",
       "       [ 0.03435782,  0.02314084,  0.02957557, ...,  0.09582867,\n",
       "        -0.02388796,  0.01308565]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_block(input_block(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287c0e5d-d52e-40fe-a282-ad89bd6619f7",
   "metadata": {},
   "source": [
    "Next, we define the prediction task. Our objective is `multi-class classification` - which is the city visited at the end of the trip session. Therefore, this is a multi-class classification task, and the default_loss in the CategoricalOutput class is `categorical_crossentropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffdcc60e-ad84-4163-b8ab-563ac207ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_task = mm.CategoricalOutput(\n",
    "    schema_model.select_by_name(target), \n",
    "    default_loss=\"categorical_crossentropy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ded1c11-e655-4342-aa95-0d38c56ce72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp = mm.Model(input_block, mlp_block, prediction_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4d613e-ddf4-4a60-9ed9-74a0a4cd7efa",
   "metadata": {},
   "source": [
    "**SequencePredictLast** class prepares sequential inputs and targets for last-item prediction. Note that the last city in each `city_id_list` column is reserved as target, and it is not used as input sequence during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c47edce-7ac5-4fe6-aa57-37282d095dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_last = mm.SequencePredictLast(schema=schema_model.select_by_tag(Tags.SEQUENCE), target=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d5c952-9663-4c52-aa05-f122e87b1c3d",
   "metadata": {},
   "source": [
    "#### 3.2.4. Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2e9aa1-a30f-42b2-afc4-454bb7a75953",
   "metadata": {},
   "source": [
    "The following information retrieval metrics are used to compute the `Top-k` accuracy of recommendation lists containing all items (see keras [documentation](https://www.tensorflow.org/ranking/api_docs/python/tfr/keras/metrics)):\n",
    "\n",
    "**Normalized Discounted Cumulative Gain (NDCG@k)**: NDCG accounts for rank of the relevant item in the recommendation list and is a more fine-grained metric than HR, which only verifies whether the relevant item is among the top-k items.\n",
    "\n",
    "**Recall@k**: Also known as HitRate@n when there is only one relevant item in the recommendation list. Recall just verifies whether the relevant item is among the top-n items.\n",
    "\n",
    "**Mean Reciprocal Rank (MRR@k)**: This is the user-averaged value of the Reciprocal Rank@k, which is the inverse rank (one divided by the rank) of the first item\n",
    "among the top-K recommended that is in the test data (see [reference](https://cran.r-project.org/web/packages/recometrics/recometrics.pdf))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763c730d-8fe8-4ae8-88b6-5381c73e8d7a",
   "metadata": {},
   "source": [
    "The goal of the [Booking.com WSDM WebTour 2021 Challenge](https://ceur-ws.org/Vol-2855/challenge_short_1.pdf) challenge was to predict (and recommend) the final city (city_id) of each trip (utrip_id). The quality of the predictions is evaluated based on the top four recommended cities for each trip (session) by using Top-4 Accuracy metric. At the [Booking.com WSDM WebTour 2021 Challenge](https://ceur-ws.org/Vol-2855/challenge_short_1.pdf)  best performing team (NVIDIA team) achieved Accuracy@4 of 0.5939, using a blend of Transformers, GRUs, and feed-forward multi-layer perceptron. Considering this, we are generating `Top@4` metric values from model training and evaluation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff8ce255-cb1d-40ef-9704-fa9e735d4946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.models.tf.metrics.topk import (\n",
    "    MRRAt,\n",
    "    NDCGAt,\n",
    "    RecallAt,\n",
    "    TopKMetricsAggregator,\n",
    ")\n",
    "metrics_agg = mm.TopKMetricsAggregator(RecallAt(4), MRRAt(4), NDCGAt(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358d3098-4128-47ec-a7ba-5f31509edd52",
   "metadata": {},
   "source": [
    "Compile and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8eaef0bc-f53f-493f-b189-b9afdde555cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE,\n",
    ")\n",
    "\n",
    "model_mlp.compile(\n",
    "    optimizer=optimizer,\n",
    "    run_eagerly=False,\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(\n",
    "        from_logits=True, \n",
    "    ),\n",
    "    metrics=[metrics_agg]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4517a742-a0aa-4295-bac6-e8bba0cbfc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "409/409 [==============================] - 34s 43ms/step - loss: 6.1123 - recall_at_4: 0.1707 - mrr_at_4: 0.1173 - ndcg_at_4: 0.1308 - regularization_loss: 0.0000e+00 - loss_batch: 6.1078\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 21s 44ms/step - loss: 4.5117 - recall_at_4: 0.4218 - mrr_at_4: 0.3053 - ndcg_at_4: 0.3348 - regularization_loss: 0.0000e+00 - loss_batch: 4.5104\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 21s 44ms/step - loss: 4.0890 - recall_at_4: 0.4561 - mrr_at_4: 0.3326 - ndcg_at_4: 0.3638 - regularization_loss: 0.0000e+00 - loss_batch: 4.0883\n",
      "CPU times: user 2min 26s, sys: 20.8 s, total: 2min 47s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model_mlp.fit(\n",
    "    train,\n",
    "    epochs=3,\n",
    "    batch_size=512,\n",
    "    pre=predict_last\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9227ff05-8123-44b1-a088-39891442834c",
   "metadata": {},
   "source": [
    "Evaluate the model using the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9500dec-a815-45ae-b96b-bb8405c4bf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 4s 42ms/step - loss: 3.5418 - recall_at_4: 0.5575 - mrr_at_4: 0.3998 - ndcg_at_4: 0.4397 - regularization_loss: 0.0000e+00 - loss_batch: 3.5547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 3.5418004989624023,\n",
       " 'recall_at_4': 0.5628074407577515,\n",
       " 'mrr_at_4': 0.40140968561172485,\n",
       " 'ndcg_at_4': 0.44224879145622253,\n",
       " 'regularization_loss': 0.0,\n",
       " 'loss_batch': 3.611255645751953}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp.evaluate(\n",
    "    valid,\n",
    "    batch_size=1024,\n",
    "    pre=predict_last,\n",
    "    return_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "032eb74f-e2ad-41bb-82b6-d32e04f9f407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model_mlp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf961ff-0971-4f8e-a3b6-9a448ae71cae",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6d8546-79e1-481c-bd5b-d8f404c0edfe",
   "metadata": {},
   "source": [
    "In this example, we focused on concepts which are relevant for a broad range of recommender system use cases- session-based recommendation task. We started with a simple architecture, an MLP model, and used high level apis provided by Merlin Models library. Note that we did not perform hyper-parameter tuning or set an optimizer scheduler or different techniques to improve the model accuracy. All of these can be applied at your end. For this tutorial we keep it simple, and demonstrate the building blocks of Merlin Models library in creating custom architectures for session-based recommendation models. \n",
    "\n",
    "In the next notebook, we will build an RNN-based model, and see if it can help us improve our accuracy metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ee14a2-af03-407f-a550-ed8ff0544b34",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f553b94-742d-4243-a496-79167b82a568",
   "metadata": {},
   "source": [
    "[1] Malte Ludewig and Dietmar Jannach. 2018. Evaluation of session-based recommendation algorithms. User Modeling and User-Adapted Interaction 28, 4-5 (2018), 331–390.<br>\n",
    "[2] Balázs Hidasi and Alexandros Karatzoglou. 2018. Recurrent neural networks with top-k gains for session-based recommendations. In Proceedings of the 27th ACMinternational conference on information and knowledge management. 843–852. <br>\n",
    "[3] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. In Proceedings of the 28th ACM international conference on information and knowledge management. 1441–1450. <br>\n",
    "[4] Shiming Sun, Yuanhe Tang, Zemei Dai, and Fu Zhou. 2019. Self-attention network for session-based recommendation with streaming data input. IEEE Access 7 (2019), 110499–110509.<br>\n",
    "[5] Gabriel De Souza P. Moreira, et al. (2021). Transformers4Rec: Bridging the Gap between NLP and Sequential / Session-Based Recommendation. RecSys'21."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca0d0e2-da1d-4e72-a362-fba7fd6c5a8d",
   "metadata": {},
   "source": [
    "Please execute the cell below to shut down the kernel before moving on to the next notebook `04-Next-item-prediction-with-LSTM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed3ac085-d8e7-4f99-83cc-173bd78971ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
