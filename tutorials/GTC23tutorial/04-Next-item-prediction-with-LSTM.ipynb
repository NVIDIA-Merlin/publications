{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96de18a-caae-4029-bb74-18b6751c123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ================================\n",
    "\n",
    "# Each user is responsible for checking the content of datasets and the\n",
    "# applicable licenses and determining if suitable for the intended use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcf73f0-556c-4e1e-8bfa-2dd90cc0e513",
   "metadata": {},
   "source": [
    "## 4. Next Item Prediction with an RNN-based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f1bdf4-79be-4953-a8b5-c44c92f6fc7a",
   "metadata": {},
   "source": [
    "In the previous example, we built, trained and evaluated an MLP model using sequential and scalar input features. Although we get promising accuracy results, MLP model does not take the sequential patterns into concern. We have to average the embedding values for the list categorical features, and aggregate (take average) the list continuos values.\n",
    "\n",
    "In this example, we use a type of Recurrent Neural Networks (RNN) - the Long Short-term Memory Networks (LSTM)[1, 2] - to do next-city prediction using a sequence of events (trip history in our example) per user in a given trip (session). As a type of RNN, an LSTM model are a class of neural networks that is being used for modeling sequence data such as time series or natural language.\n",
    "\n",
    "There is obviously some sequential patterns in our dataset that we want to capture to provide more relevant recommendations. We can do that using an LSTM model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3297e0e0-9b6c-4d30-a6c5-55905d77daed",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/RNN.png\" width=300 height=200/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85cf072-49fa-4e0f-931b-32656a187bd3",
   "metadata": {},
   "source": [
    "In general, LSTM models are coupled with Causal Language Modeling (CLM) pre-training scheme, which is the task of predicting the token following a sequence of tokens, where the model only attends to the left context, i.e. models the probability of a token given the previous tokens (city_ids in our case) in a sequence [3]. \n",
    "\n",
    "In our case, the input of the LSTM layer is a representation of the user interaction, the internal LSTM hidden state encodes a representation of the session based on past interactions and the outputs are the next-item predictions. For a given trip session, our proposed LSTM model generates logit values as predictions for the user's preference of the next item in the sequence. These logit values represent the likelihood of each item being the next one, and are based on the hidden representation of the last item in the session.\n",
    "\n",
    "To do so, we train an LSTM model using [SequencePredictLast](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/transforms/sequence.py#L254) technique, where we use the entire sequence to predict the next item (city), rather than performing a sliding approach to do next-item prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757dc39a-6d8f-4762-8921-0af91a973457",
   "metadata": {},
   "source": [
    "**Learning Objectives:**</br>\n",
    "\n",
    "In this lab, participants will learn:\n",
    "- building an LSTM model using Merlin Models\n",
    "- training and evaluating the LSTM model using sequential categorical and continuous input features for next-item prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e382d0f1-0e35-4b08-b810-967a2adb5088",
   "metadata": {},
   "source": [
    "### 4.1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f47581-aa15-4796-9648-f5f00713de6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 16:02:17.049101: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "import glob\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dfde68-71b3-4ae5-93c9-ea76d9a7e4ea",
   "metadata": {},
   "source": [
    "Let's set the seeds to mitigate flakiness/randomness and to make model execution deterministic as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99c85a16-17cb-44a3-ac7e-5d6895d59ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bcdcc1-88bb-4eab-ac79-6fa8f8cdebc9",
   "metadata": {},
   "source": [
    "Import Merlin APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edd529a7-0151-4ff6-9440-0328dfbfcc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "2023-02-27 16:02:21.970490: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 16:02:23.965928: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-02-27 16:02:23.966023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1637] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16249 MB memory:  -> device: 0, name: Quadro GV100, pci bus id: 0000:2d:00.0, compute capability: 7.0\n",
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from merlin.schema.tags import Tags\n",
    "from merlin.io.dataset import Dataset\n",
    "\n",
    "import merlin.models.tf as mm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e482e548-6720-4a68-bfc9-013127bb2f68",
   "metadata": {},
   "source": [
    "Define data path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "286e75c1-dd7c-49af-b3bf-ecd9d402079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = os.environ.get(\n",
    "    \"DATA_FOLDER\", \n",
    "    '/workspace/data/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c27fc6d-cbcf-4d5f-bb09-23c70e496427",
   "metadata": {},
   "source": [
    "Read in train and validation sets as Merlin Dataset objects. Note that these datasets have schema associated to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb714228-92d5-4e6a-a8fc-b618727c1b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train = Dataset(os.path.join(DATA_FOLDER, \"train/*.parquet\"))\n",
    "valid = Dataset(os.path.join(DATA_FOLDER, \"valid/*.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07857906-2c81-4bbe-91be-a3ba201ab09a",
   "metadata": {},
   "source": [
    "Define target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0414de6b-e5b8-4d69-88e0-afd70b63d7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'city_id_list'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = train.schema.select_by_tag(Tags.SEQUENCE).column_names[0]\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6443fc95-5c75-4ecc-89fd-8d427c794048",
   "metadata": {},
   "source": [
    "Let's start with defining our hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d9d322-6348-4c78-af91-3aafd9a0211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = int(os.environ.get(\n",
    "    \"EPOCHS\", \n",
    "    '3'\n",
    "))\n",
    "\n",
    "dmodel = int(os.environ.get(\n",
    "    \"dmodel\", \n",
    "    '64'\n",
    "))\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00bc279-d32a-4099-991d-fb9c700b0e68",
   "metadata": {},
   "source": [
    "Here we define schema object. We create a subschema by selecting the input features with their names using `select_by_name` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8d297e5-855f-4cac-b4a4-771905ac942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.schema = train.schema.select_by_name(['city_id_list','booker_country_list', 'hotel_country_list',\n",
    "                                            'weekday_checkin_list','weekday_checkout_list',\n",
    "                                            'month_checkin_list','num_city_visited', 'length_of_stay_list']\n",
    "                                          )\n",
    "\n",
    "valid.schema = train.schema\n",
    "\n",
    "seq_schema =train.schema.select_by_tag(Tags.SEQUENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fef0c423-49c9-45ee-8d38-228d0376b556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.start_index</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "      <th>properties.value_count.min</th>\n",
       "      <th>properties.value_count.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>city_id_list</td>\n",
       "      <td>(Tags.ITEM_ID, Tags.ID, Tags.SEQUENCE, Tags.CA...</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.city_id.parquet</td>\n",
       "      <td>39665.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39664.0</td>\n",
       "      <td>city_id</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>booker_country_list</td>\n",
       "      <td>(Tags.LIST, Tags.CATEGORICAL, Tags.SEQUENCE)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.booker_country_hotel_coun...</td>\n",
       "      <td>196.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>booker_country_hotel_country</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hotel_country_list</td>\n",
       "      <td>(Tags.LIST, Tags.CATEGORICAL, Tags.SEQUENCE)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.booker_country_hotel_coun...</td>\n",
       "      <td>196.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>booker_country_hotel_country</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weekday_checkin_list</td>\n",
       "      <td>(Tags.LIST, Tags.CATEGORICAL, Tags.SEQUENCE)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.checkin.parquet</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>checkin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weekday_checkout_list</td>\n",
       "      <td>(Tags.LIST, Tags.CATEGORICAL, Tags.SEQUENCE)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.checkout.parquet</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>checkout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>month_checkin_list</td>\n",
       "      <td>(Tags.LIST, Tags.CATEGORICAL, Tags.SEQUENCE)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.checkin.parquet</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>checkin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_city_visited</td>\n",
       "      <td>(Tags.CONTEXT, Tags.CONTINUOUS)</td>\n",
       "      <td>DType(name='float64', element_type=&lt;ElementTyp...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.city_id.parquet</td>\n",
       "      <td>39665.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39664.0</td>\n",
       "      <td>city_id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>length_of_stay_list</td>\n",
       "      <td>(Tags.LIST, Tags.SEQUENCE, Tags.CONTINUOUS)</td>\n",
       "      <td>DType(name='float64', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'city_id_list', 'tags': {<Tags.ITEM_ID: 'item_id'>, <Tags.ID: 'id'>, <Tags.SEQUENCE: 'sequence'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>, <Tags.ITEM: 'item'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.city_id.parquet', 'embedding_sizes': {'cardinality': 39665.0, 'dimension': 512.0}, 'domain': {'min': 0, 'max': 39664, 'name': 'city_id'}, 'value_count': {'min': 0.0, 'max': 10.0}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0.0, max=None), Dimension(min=0.0, max=10.0)))), 'is_list': True, 'is_ragged': True}, {'name': 'booker_country_list', 'tags': {<Tags.LIST: 'list'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.SEQUENCE: 'sequence'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.booker_country_hotel_country.parquet', 'embedding_sizes': {'cardinality': 196.0, 'dimension': 31.0}, 'domain': {'min': 0, 'max': 195, 'name': 'booker_country_hotel_country'}, 'value_count': {'min': 0.0, 'max': 10.0}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0.0, max=None), Dimension(min=0.0, max=10.0)))), 'is_list': True, 'is_ragged': True}, {'name': 'hotel_country_list', 'tags': {<Tags.LIST: 'list'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.SEQUENCE: 'sequence'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.booker_country_hotel_country.parquet', 'embedding_sizes': {'cardinality': 196.0, 'dimension': 31.0}, 'domain': {'min': 0, 'max': 195, 'name': 'booker_country_hotel_country'}, 'value_count': {'min': 0.0, 'max': 10.0}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0.0, max=None), Dimension(min=0.0, max=10.0)))), 'is_list': True, 'is_ragged': True}, {'name': 'weekday_checkin_list', 'tags': {<Tags.LIST: 'list'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.SEQUENCE: 'sequence'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.checkin.parquet', 'embedding_sizes': {'cardinality': 8.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 7, 'name': 'checkin'}, 'value_count': {'min': 0.0, 'max': 10.0}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0.0, max=None), Dimension(min=0.0, max=10.0)))), 'is_list': True, 'is_ragged': True}, {'name': 'weekday_checkout_list', 'tags': {<Tags.LIST: 'list'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.SEQUENCE: 'sequence'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.checkout.parquet', 'embedding_sizes': {'cardinality': 8.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 7, 'name': 'checkout'}, 'value_count': {'min': 0.0, 'max': 10.0}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0.0, max=None), Dimension(min=0.0, max=10.0)))), 'is_list': True, 'is_ragged': True}, {'name': 'month_checkin_list', 'tags': {<Tags.LIST: 'list'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.SEQUENCE: 'sequence'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.checkin.parquet', 'embedding_sizes': {'cardinality': 8.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 7, 'name': 'checkin'}, 'value_count': {'min': 0.0, 'max': 10.0}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0.0, max=None), Dimension(min=0.0, max=10.0)))), 'is_list': True, 'is_ragged': True}, {'name': 'num_city_visited', 'tags': {<Tags.CONTEXT: 'context'>, <Tags.CONTINUOUS: 'continuous'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.city_id.parquet', 'embedding_sizes': {'cardinality': 39665.0, 'dimension': 512.0}, 'domain': {'min': 0.0, 'max': 39664.0, 'name': 'city_id'}}, 'dtype': DType(name='float64', element_type=<ElementType.Float: 'float'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0.0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'length_of_stay_list', 'tags': {<Tags.LIST: 'list'>, <Tags.SEQUENCE: 'sequence'>, <Tags.CONTINUOUS: 'continuous'>}, 'properties': {'value_count': {'min': 0.0, 'max': 10.0}}, 'dtype': DType(name='float64', element_type=<ElementType.Float: 'float'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0.0, max=None), Dimension(min=0.0, max=10.0)))), 'is_list': True, 'is_ragged': True}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb5d29-b4d1-48bd-b10b-10e677aaab20",
   "metadata": {},
   "source": [
    "Define the context schema which represents the context features, which is `num_city_visited` in our case. The reason we define a separate context schema for the context feature is that because, we need to broadcast this scalar feature to list feature. For that we need its schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c757d2f0-cf70-4c3c-ad62-43a58f4d615b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.start_index</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_city_visited</td>\n",
       "      <td>(Tags.CONTEXT, Tags.CONTINUOUS)</td>\n",
       "      <td>DType(name='float64', element_type=&lt;ElementTyp...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.city_id.parquet</td>\n",
       "      <td>39665.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39664.0</td>\n",
       "      <td>city_id</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'num_city_visited', 'tags': {<Tags.CONTEXT: 'context'>, <Tags.CONTINUOUS: 'continuous'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.city_id.parquet', 'embedding_sizes': {'cardinality': 39665.0, 'dimension': 512.0}, 'domain': {'min': 0.0, 'max': 39664.0, 'name': 'city_id'}}, 'dtype': DType(name='float64', element_type=<ElementType.Float: 'float'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0.0, max=None),))), 'is_list': False, 'is_ragged': False}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_schema = train.schema.select_by_tag(Tags.CONTEXT)\n",
    "context_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431c1fd9-8025-4b3f-a7a6-8bd975f3fa3e",
   "metadata": {},
   "source": [
    "We define the embedding dimension of certain categorical features. Note that with `dim` arg, wefeed a fix dimension for all  categorical features. In this example, we set the embedding dimension as `16` for each categorical feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b8e3f4-f3ac-401a-b4fb-c806f67e7b38",
   "metadata": {},
   "source": [
    "### 4.2. Build an LSTM model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154d6ece-d351-4de2-aa62-018268af29b6",
   "metadata": {},
   "source": [
    "In this section, we train a LSTM model which enables straight (past) sequence to be used. The input block concatenates the embedding vectors for all sequential features per step, and then concatenates the continuous features that we created in the `ETL-with-NVTabular` notebook to each input sequence. The concatenated vectors are processed by a LSTM architecture. Then we connect it with a Multi-Layer Perceptron Block. We use the last item in the `city_id_list` column as target.\n",
    "\n",
    "We visualize the model architecture in the figure below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb21ac-a449-480f-bb25-edf2e4d97002",
   "metadata": {},
   "source": [
    "<img src=\"./images/LSTM.png\" width=600 height=400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9ed827-6a7b-473e-9c18-805b7919c6c8",
   "metadata": {},
   "source": [
    "Define the input block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ca1f6a9-b1ce-42ed-ada4-64cfbbb96aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_block = mm.InputBlockV2(\n",
    "    train.schema,\n",
    "    embeddings=mm.Embeddings(\n",
    "        seq_schema.select_by_tag(Tags.CATEGORICAL), \n",
    "        sequence_combiner=None,\n",
    "        dim=16\n",
    "        ),\n",
    "    post=mm.BroadcastToSequence(context_schema, seq_schema),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26393ade-1373-441c-92b4-eeb227dd3a80",
   "metadata": {},
   "source": [
    "If you noticed, here we set `sequence_combiner` to None, since, we do not want to combine the embeddings for each position in a given sequence.\n",
    "\n",
    "We also add post argument in the `InputBlockV2` to broadcast the scalar features to list features. With [BroadcastToSequence](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/transforms/features.py#L814) class, we are able to replicate the scalar value (e.g. `num_city_visited` in our example) for each position in the sequence to match the timesteps of sequence features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d380dc9e-e725-4023-85e0-b56b03e4d209",
   "metadata": {},
   "source": [
    "Let's check the output shape of the input_block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f179a393-a039-4415-9414-ed5f77865515",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = mm.sample_batch(train, batch_size=BATCH_SIZE, include_targets=False, to_ragged=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "761f57b1-ce8a-4804-8611-7cd18a572bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1024, None, 98])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_block(batch).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92a90ac-1f27-4c3d-92e8-ca7edcdb4fb4",
   "metadata": {},
   "source": [
    "We obtain a 3-D sequence representation (`batch_size, sequence_length, sum_of_emb_dim_of_features + 1-d of the continuous features`). Note that total embedding dimension for categorical features is 96, and extra dimensions comes from two continuous input features (length_of_stay_list and num_city_visited). The sequence_length dimension is printed out as `None`, because it is a variable length given a batch. That's why we get the sequence_length dim printed as `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8adbb2b-9251-42ab-834e-7a1bcbde2210",
   "metadata": {},
   "source": [
    "Once we define the input block, we can easily connect it to an LSTM block (layer) using [tf.keras.layers.LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM) api. Note that we use `connect()` method to do so. We set the `units` parameter as `64`, which represents dimensionality of the output space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "175ef567-23bf-46f1-94a6-7a63896648ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "dense_block =input_block.connect(tf.keras.layers.LSTM(64,\n",
    "        return_sequences=False, \n",
    "        kernel_regularizer=regularizers.l2(1e-4),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397e0b24-b762-4776-b0ec-dd4dedbdfe82",
   "metadata": {},
   "source": [
    "When `return_sequences` is set to `False` in `tf.keras` LSTM layers, only the last hidden state output (h<N>) is returned, which captures an abstract representation of the input sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec2a083-bbc2-48ef-9034-f298ce90cacc",
   "metadata": {},
   "source": [
    "We can add an MLP block as a projection layer. We noticed that adding an extra layer increases the accuracy metrics in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2a69ef2-9cab-4d0e-b36e-e6f7f57a1e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_block = mm.MLPBlock(\n",
    "                [128,dmodel],\n",
    "                activation='relu',\n",
    "                no_activation_last_layer=True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606d9bad-eaaf-4d48-92ac-ebb4fc8e6943",
   "metadata": {},
   "source": [
    "Next, we define the prediction task. Our objective is `multi-class classification` - which is the city visited at the end of the trip session. Therefore, this is a multi-class classification task, and the default_loss in the CategoricalOutput class is `categorical_crossentropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb322952-16f7-475b-9060-ba33d4f8bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_task = mm.CategoricalOutput(\n",
    "    seq_schema.select_by_name(target), \n",
    "    default_loss=\"categorical_crossentropy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1c16b22-7da2-4d53-8734-807c5fa25919",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = mm.Model(dense_block, mlp_block, prediction_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a735b9-ae16-4c6f-86b5-86524fd25f7b",
   "metadata": {},
   "source": [
    "Define optimizer and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15e61762-55e8-4f74-ad70-294eb741dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE\n",
    ")\n",
    "\n",
    "model_lstm.compile(\n",
    "    optimizer=optimizer,\n",
    "    run_eagerly=False,\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(\n",
    "        from_logits=True, \n",
    "    ),\n",
    "    metrics=mm.TopKMetricsAggregator.default_metrics(top_ks=[4])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee03b88-7be1-4f07-8fb7-5fd8c9992ff7",
   "metadata": {},
   "source": [
    "The [SequencePredictLast](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/transforms/sequence.py#L254) class indicates that the last item in the sequence is the target. As a result, all the sequential input features are truncated before the last position, and the target is extracted as the last element of the sequence of city_ids. Based on that LSTM should return the hidden representation of the last item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afb20b0d-e1ba-4072-ba6c-e0e447c3244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_last = mm.SequencePredictLast(schema=seq_schema.select_by_tag(Tags.SEQUENCE), target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf462ffe-dd2b-4c5a-89c6-1f88a33648a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "2023-02-27 15:58:51.148439: I tensorflow/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/sequential_block_3/lstm/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/sequential_block_3/concat_features/RaggedConcat/Slice_1:0\", shape=(None, None), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/sequential_block_3/concat_features/RaggedConcat/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/sequential_block_3/lstm/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/sequential_block_3/concat_features/RaggedConcat/Slice_3:0\", shape=(None, None), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/sequential_block_3/concat_features/RaggedConcat/Shape_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/sequential_block_3/lstm/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/sequential_block_3/concat_features/RaggedConcat/Slice_5:0\", shape=(None, None), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/sequential_block_3/concat_features/RaggedConcat/Shape_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/sequential_block_3/lstm/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/sequential_block_3/concat_features/RaggedConcat/Slice_7:0\", shape=(None, None), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/sequential_block_3/concat_features/RaggedConcat/Shape_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/sequential_block_3/lstm/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/sequential_block_3/concat_features/RaggedConcat/Slice_9:0\", shape=(None, None), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/sequential_block_3/concat_features/RaggedConcat/Shape_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/sequential_block_3/lstm/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/sequential_block_3/concat_features/RaggedConcat/Slice_11:0\", shape=(None, None), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/sequential_block_3/concat_features/RaggedConcat/Shape_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/sequential_block_3/lstm/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/sequential_block_3/concat_features/RaggedConcat/Slice_13:0\", shape=(None, None), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/sequential_block_3/concat_features/RaggedConcat/Shape_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/sequential_block_3/lstm/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/sequential_block_3/concat_features/RaggedConcat/Slice_15:0\", shape=(None, None), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/sequential_block_3/concat_features/RaggedConcat/Shape_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 33s 59ms/step - loss: 6.9439 - recall_at_4: 0.1006 - mrr_at_4: 0.0630 - ndcg_at_4: 0.0724 - map_at_4: 0.0630 - precision_at_4: 0.0251 - regularization_loss: 0.0112 - loss_batch: 6.9308\n",
      "Epoch 2/3\n",
      "205/205 [==============================] - 14s 58ms/step - loss: 4.9218 - recall_at_4: 0.3742 - mrr_at_4: 0.2716 - ndcg_at_4: 0.2975 - map_at_4: 0.2716 - precision_at_4: 0.0935 - regularization_loss: 0.0160 - loss_batch: 4.9164\n",
      "Epoch 3/3\n",
      "205/205 [==============================] - 14s 59ms/step - loss: 4.2418 - recall_at_4: 0.4530 - mrr_at_4: 0.3381 - ndcg_at_4: 0.3671 - map_at_4: 0.3381 - precision_at_4: 0.1132 - regularization_loss: 0.0171 - loss_batch: 4.2378\n",
      "CPU times: user 1min 35s, sys: 10.9 s, total: 1min 46s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model_lstm.fit(\n",
    "    train,\n",
    "    epochs=3,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    pre=predict_last\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d2e5cf-8106-4571-9a66-670c77427328",
   "metadata": {},
   "source": [
    "Evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de457497-d90e-42be-8b8a-f13684e3a98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 6s 45ms/step - loss: 3.3902 - recall_at_4: 0.5818 - mrr_at_4: 0.4346 - ndcg_at_4: 0.4719 - map_at_4: 0.4346 - precision_at_4: 0.1455 - regularization_loss: 0.0167 - loss_batch: 3.3785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 3.390162706375122,\n",
       " 'recall_at_4': 0.583443284034729,\n",
       " 'mrr_at_4': 0.4348030388355255,\n",
       " 'ndcg_at_4': 0.472442090511322,\n",
       " 'map_at_4': 0.4348030388355255,\n",
       " 'precision_at_4': 0.14586082100868225,\n",
       " 'regularization_loss': 0.016703125089406967,\n",
       " 'loss_batch': 3.327507495880127}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.evaluate(\n",
    "    valid,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    pre=predict_last,\n",
    "    return_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf09b63e-5be3-40a0-9d11-1393492879dd",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08716e68-0216-4e60-a3f7-54e25fca0ee6",
   "metadata": {},
   "source": [
    "In this lab, we learned how to build an RNN-based model to leverage the sequential input features for next-item prediction task. We used an LSTM model, and we can observe that this architecture gave us some boost in model accuracy metrics. This might not be suprising since with LSTM we do not have to average the sequential feature embeddings as we did in MLP architecture.\n",
    "\n",
    "Note that we do not perform hyperparameter tuning, we used the same hyperparameters for MLP and LSTM models but this does not mean that each model gives good performance with the same set of hyperparameters. \n",
    "\n",
    "At this point, you might still want to explore different architectures, and to try more sophisticated, yet computationaly more expensive ones, like Transformers-based architectures. Let's move on to the next notebook `05-Next-item-prediction-with-Transformers` to build one using Merlin Models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b9f3d2-2989-44aa-ad2b-e5a0d4ebede3",
   "metadata": {},
   "source": [
    "Please execute the cell below to shut down the kernel before moving on to the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d04e59b-51d3-43bc-9177-97517a04d077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e0e819-d550-49f1-9275-067d95d17531",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d707e50d-161c-405f-ae78-eb6bbbe90de0",
   "metadata": {},
   "source": [
    "[1] Hochreiter, Sepp, and JÃ¼rgen Schmidhuber. \"Long short-term memory.\" Neural computation 9.8 (1997): 1735-1780. online available: https://arxiv.org/pdf/1909.09586.pdf <br>\n",
    "[2] Staudemeyer, Ralf C., and Eric Rothstein Morris. (2019). \"Understanding LSTM-a tutorial into long short-term memory recurrent neural networks.\" online available: https://arxiv.org/pdf/1909.09586.pdf<br>\n",
    "[3] Lample, Guillaume, and Alexis Conneau. \"Cross-lingual language model pretraining.\" arXiv preprint arXiv:1901.07291"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
