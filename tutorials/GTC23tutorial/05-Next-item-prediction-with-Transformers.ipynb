{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96de18a-caae-4029-bb74-18b6751c123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ================================\n",
    "\n",
    "# Each user is responsible for checking the content of datasets and the\n",
    "# applicable licenses and determining if suitable for the intended use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964146b4-8561-4810-8e8e-368cd4828afb",
   "metadata": {},
   "source": [
    "## 5. Next item prediction with a Transformer-based model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e7ce3a-c387-45e3-8a04-62abc1c50cc4",
   "metadata": {},
   "source": [
    "In recent years, several deep learning-based algorithms have been proposed for recommendation systems while its adoption in industry deployments have been steeply growing. In particular, NLP inspired approaches have been successfully adapted for sequential and session-based recommendation problems, which are important for many domains like e-commerce, news and streaming media. Session-Based Recommender Systems (SBRS) have been proposed to model the sequence of interactions within the current user session, where a session is a short sequence of user interactions typically bounded by user inactivity. They have recently gained popularity due to their ability to capture short-term or contextual user preferences towards items.\n",
    "\n",
    "The field of NLP has evolved significantly within the last decade, particularly due to the increased usage of deep learning. As a result, state of the art NLP approaches have inspired RecSys practitioners and researchers to adapt those architectures, especially for sequential and session-based recommendation problems. Here, we use one of the state-of-the-art Transformer-based architecture, XLNet with Causal Language Modeling (CLM) training technique for multi-class classification task. For this, we leverage the popular HuggingFace’s Transformers NLP library and make it possible to experiment with cutting-edge implementation of such architectures for sequential and session-based recommendation problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ece498b-8775-4448-b840-a0e41bb98254",
   "metadata": {},
   "source": [
    "### 5.1.1. What's Transformers?\n",
    "The Transformer is a competitive alternative to the models using Recurrent Neural Networks (RNNs) for a range of sequence modeling tasks. The Transformer architecture [1] was introduced as a novel architecture in NLP domain that aims to solve sequence-to-sequence tasks relying entirely on self-attention mechanism to compute representations of its input and output. Hence, the Transformer overperforms RNNs with their three mechanisms:\n",
    "\n",
    "- Non-sequential: Transformers network is parallelized where as RNN computations are inherently sequential. That resulted in significant speed-up in the training time.<br>\n",
    "- Self-attention mechanisms: Transformers rely entirely on self-attention mechanisms that directly model relationships between all item-ids in a sequence.\n",
    "- Positional encodings: A representation of the location or “position” of items in a sequence which is used to give the order context to the model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e1459d-9497-4d55-ae15-54c00154d0ae",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/rnn_transformers.png\" width=600 height=200/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b97311-4345-4b16-866d-138ebe670767",
   "metadata": {},
   "source": [
    "**Learning Objectives:**\n",
    "- Train and evaluate a transformer-based model (XLNet) for next-item prediction task\n",
    "- Apply weight-tying technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f47581-aa15-4796-9648-f5f00713de6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 00:09:07.825921: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708783c0-65b7-422a-99c0-4716bd1cf14a",
   "metadata": {},
   "source": [
    "Sets all random seeds for the program (Python, NumPy, and TensorFlow), to make Keras program deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfa6e4fb-8905-403c-83aa-80daddbc45a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=42\n",
    "tf.keras.utils.set_random_seed(\n",
    "    seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2d2c407-e6b7-47c9-8969-a99ac4486e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "2023-03-04 00:09:10.901210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-04 00:09:10.901696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-04 00:09:10.901834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-03-04 00:09:11.585567: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-04 00:09:11.586170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-04 00:09:11.586379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-04 00:09:11.586511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-04 00:09:12.510738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-04 00:09:12.510945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-04 00:09:12.511086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-04 00:09:12.511186: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-03-04 00:09:12.511254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1637] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11514 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from merlin.schema.tags import Tags\n",
    "from merlin.io.dataset import Dataset\n",
    "import merlin.models.tf as mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "286e75c1-dd7c-49af-b3bf-ecd9d402079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = os.environ.get(\n",
    "    \"DATA_FOLDER\", \n",
    "    '/workspace/data/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb714228-92d5-4e6a-a8fc-b618727c1b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train = Dataset(os.path.join(DATA_FOLDER, \"train/*.parquet\"))\n",
    "valid = Dataset(os.path.join(DATA_FOLDER, \"valid/*.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0414de6b-e5b8-4d69-88e0-afd70b63d7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'city_id_list'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = train.schema.select_by_tag(Tags.SEQUENCE).column_names[0]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d9d322-6348-4c78-af91-3aafd9a0211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = int(os.environ.get(\n",
    "    \"EPOCHS\", \n",
    "    '3'\n",
    "))\n",
    "\n",
    "dmodel = int(os.environ.get(\n",
    "    \"dmodel\", \n",
    "    '64'\n",
    "))\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 0.003"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4419ab05-737e-4fe9-aecc-3337650a3a3d",
   "metadata": {},
   "source": [
    "### 5.1.2. Building an XLNET Model with Merlin Models TensorFlow API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f550e016-bf48-46a8-b0ea-b8733b644dbe",
   "metadata": {},
   "source": [
    "The Merlin Models Transformer API consists of wrapping the HuggingFace transformer layers inside a Merlin Models Block class, called `TransformerBlock`, and offering different pre-training approaches to train and evaluate the model on recsys data. \n",
    "\n",
    "Using the Merlin Transformer API, you can define your transformer-based model with all common recsys techniques such as negative sampling,top-k candidates generation,  and weight-tying.\n",
    "\n",
    "The API consists of three main steps: \n",
    "\n",
    "- **Inputs preparation:** Implement specialized pre-processing blocks that involve set embeddings expected by the HuggingFace transformer layer, including generating mask information at inference (if needed), conversion of ragged inputs to dense tensors, and preparation of the dictionary inputs required by the HF layer.\n",
    "\n",
    "- **Target generation**: Geneate targets from the input sequence of candidate IDs using [SequenceTransform](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/transforms/sequence.py#L77) instances based on the training and evaluation strategy.\n",
    "\n",
    "- **Output post-processing:** Implement specialized post-processing blocks that involve selecting relevant information from the HF layer's output, converting the output hidden representation to a RaggedTensor, and summarizing the sequence of hidden vectors into one representing the entire input sequence. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157139dc-d1ca-43fc-aed6-c5a34b5e9eac",
   "metadata": {},
   "source": [
    "We can do high-level visualization of the building blocks of the Merlin Transformers API as below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee148667-1027-4d84-bfbd-6b5f2da98be8",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/TransformerAPI.png\" width=600 height=200/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a543cdaa-2055-431a-ab3d-f4b99c6e6681",
   "metadata": {},
   "source": [
    "Let's visualize the workflow inside of the `TransformerBlock`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc155fa-5ad1-47a4-b4d4-ae89298c4207",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/transformerblock.png\" width=800 height=200/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4108ffaf-a15e-49a9-8956-b3ec5aa6df26",
   "metadata": {},
   "source": [
    "Now, let's get started with reading in train and validation sets as Merlin Dataset objects. Note that these datasets have schema associated to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a668316-ca22-458c-a9d1-f2858f31a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Dataset(os.path.join(DATA_FOLDER, \"train/*.parquet\"))\n",
    "valid = Dataset(os.path.join(DATA_FOLDER, \"valid/*.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e423fd0a-f669-482d-9941-833f2f63471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.schema = train.schema.select_by_name(['city_id_list','booker_country_list', 'hotel_country_list',\n",
    "                                            'weekday_checkin_list','weekday_checkout_list',\n",
    "                                            'month_checkin_list','num_city_visited', 'length_of_stay_list']\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6230f288-5178-4148-af1c-8b743c9e0a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_schema = train.schema.select_by_tag(Tags.SEQUENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "870bbe49-a31a-41d3-8828-e3c8700ff77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_schema = train.schema.select_by_tag(Tags.CONTEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a89967ee-6026-45f4-a971-f26eec08c696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'city_id_list'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_schema = train.schema.select_by_tag(Tags.ITEM_ID)\n",
    "target = target_schema.column_names[0]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9cce3f7-b001-4609-a7a0-99df20bdbff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_block = mm.MLPBlock(\n",
    "                [128,dmodel],\n",
    "                activation='relu',\n",
    "                no_activation_last_layer=True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6435ca89-3cd2-4a1c-90ca-70f2f0f17253",
   "metadata": {},
   "source": [
    "Define the `input_block`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91901797-b793-4e83-bb3a-f31b6ff6af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_block = mm.InputBlockV2(\n",
    "    train.schema,    \n",
    "    embeddings=mm.Embeddings(\n",
    "        seq_schema.select_by_tag(Tags.CATEGORICAL), \n",
    "        sequence_combiner=None,\n",
    "        dim=dmodel\n",
    "        ),\n",
    "    post=mm.BroadcastToSequence(context_schema, seq_schema),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0286649-06d2-4ebc-9624-6edfbb9ae9a7",
   "metadata": {},
   "source": [
    "We can check the output shape of the input block using a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "878a3c30-dec6-4740-843f-a94e895c67f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, None, 386)\n"
     ]
    }
   ],
   "source": [
    "batch = mm.sample_batch(train, batch_size=128, include_targets=False, to_ragged=True)\n",
    "print(input_block(batch).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcf4607-eec1-4ec3-9af1-f009b5c024e6",
   "metadata": {},
   "source": [
    "Let's create a sequential block where we connect sequential inputs block (i.e., a SequentialLayer represents a sequence of Keras layers) with MLPBlock and then XLNetBlock. XLNet architecture [2] was originally proposed to be trained with the Permutation Language Modeling (PLM) technique, that combines the advantages of autoregressive (Causal LM) and autoencoding (Masked LM). However, with Merlin Models TF API, we are able to decouple model architecture and masking approach. With that, in this example, we perform next-item prediction with Causal Language Modeling (CLM) approach, which involves an auto-regressive model with sliding window predictions, where only the left context of position `n` is used to predict target `n+1`.<br>\n",
    "\n",
    "Below we use MLPBlock as a projection block to match the output dimensions of the seq_inputs block with the transformer block. In other words, due to residual connection in the Transformer model, we add an MLPBlock in the model pipeline. The output dim of the input block should match with the hidden dimension (d_model) of the XLNetBlock."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e031cf-2d1c-481e-a571-05684952381e",
   "metadata": {},
   "source": [
    "Here we instantiate an [XLNet block](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/transformers/block.py#L399) by setting the parameters (e.g., d_model, n_head, n_layer, etc.). You can learn more about these parameters [here](https://huggingface.co/docs/transformers/model_doc/xlnet).\n",
    "\n",
    "- d_model:  Dimensionality of the encoder layers and the pooler layer.\n",
    "- n_head:  Number of attention heads for each attention layer in the Transformer encoder.\n",
    "- n_layer: Number of hidden layers in the Transformer encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a498c8dc-5942-4f59-b2cb-2f5da3a1a478",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet_block = mm.XLNetBlock(d_model=dmodel, n_head=4, n_layer=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b99aa0f-92ef-473f-9a79-e30c90ab4856",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_block = mm.SequentialBlock(\n",
    "    input_block,\n",
    "    mlp_block,\n",
    "    xlnet_block\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4978f2ed-3db4-49c5-a86e-950246201c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_block2 = mm.MLPBlock(\n",
    "                [128,dmodel],\n",
    "                activation='relu',\n",
    "                no_activation_last_layer=True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eef09b-5eb1-4031-8119-16ec723d3437",
   "metadata": {},
   "source": [
    "[CategoricalOutput](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/outputs/classification.py#L114https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/outputs/classification.py#L114) class has the functionality to do `weight-tying`, when we provide the EmbeddingTable related to the target feature in the `to_call` method. \n",
    "\n",
    "**Weight Tying:** Sharing the weight matrix between input-to-embedding layer and output-to-softmax layer. That is, instead of using two weight matrices, we just use only one weight matrix. The intuition behind doing so is to combat the problem of overfitting. Thus, weight tying can be considered as a form of regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1abb3a2f-9086-447e-8c05-70f240d1e2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city_id\n"
     ]
    }
   ],
   "source": [
    "item_id_name = train.schema.select_by_tag(Tags.ITEM_ID).first.properties['domain']['name']\n",
    "print(item_id_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18c63055-b97e-4d47-b443-95bf0cedb57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_task = mm.CategoricalOutput(\n",
    "    to_call=input_block[\"categorical\"][item_id_name],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e551f18-580a-4f37-943f-cdbf3dfb5315",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transformer = mm.Model(dense_block, mlp_block2, prediction_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d8d3a0a-f270-4f0f-8766-4bb86e563d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6f28ad-ab12-4173-b9bd-3b485d7fe98b",
   "metadata": {},
   "source": [
    "#### 5.1.2.1. Next-item prediction with Causal Language Modeling (CLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a17e71-7edf-4556-b87b-316dec9e76b1",
   "metadata": {},
   "source": [
    "To be able to train our XLNet architecture with CLM masking technique, we need two sequence transform classes: `SequencePredictNext` and `SequencePredictLast`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13513eba-ac3f-4e8b-a89c-457f932b6934",
   "metadata": {},
   "source": [
    "[SequencePredictNext](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/transforms/sequence.py): Prepares sequential inputs and targets for next-item prediction. The target is extracted from the shifted sequence of item ids and the sequential input features are truncated in the last position. With this traning technique, we are able to train XLNet model with Casual Language Modeling (CLM) approach.\n",
    "\n",
    "[SequencePredictLast](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/transforms/sequence.py): Prepares sequential inputs and targets for last-item prediction. The target is extracted from the last element of sequence of item ids and the sequential input features are truncated before the last position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a812c452-1073-4819-8bc2-8eead48d7ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n",
      "2023-03-04 00:09:25.149201: I tensorflow/stream_executor/cuda/cuda_blas.cc:1633] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-03-04 00:09:25.361888: I tensorflow/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/sequential_block_4/xl_net_block/prepare_transformer_inputs_4/RaggedToTensor_1/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/sequential_block_4/xl_net_block/prepare_transformer_inputs_4/RaggedToTensor_1/boolean_mask/GatherV2:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/sequential_block_4/xl_net_block/prepare_transformer_inputs_4/RaggedToTensor_1/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['model/mask_emb:0', 'transformer/layer_._0/rel_attn/r_s_bias:0', 'transformer/layer_._0/rel_attn/seg_embed:0', 'transformer/layer_._1/rel_attn/r_s_bias:0', 'transformer/layer_._1/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['model/mask_emb:0', 'transformer/layer_._0/rel_attn/r_s_bias:0', 'transformer/layer_._0/rel_attn/seg_embed:0', 'transformer/layer_._1/rel_attn/r_s_bias:0', 'transformer/layer_._1/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "409/409 [==============================] - 35s 52ms/step - loss: 6.5380 - recall_at_4: 0.0784 - mrr_at_4: 0.0484 - ndcg_at_4: 0.0559 - map_at_4: 0.0484 - precision_at_4: 0.0196 - regularization_loss: 0.0000e+00 - loss_batch: 6.5306\n",
      "Epoch 2/3\n",
      "409/409 [==============================] - 21s 51ms/step - loss: 4.1045 - recall_at_4: 0.4346 - mrr_at_4: 0.3107 - ndcg_at_4: 0.3420 - map_at_4: 0.3107 - precision_at_4: 0.1087 - regularization_loss: 0.0000e+00 - loss_batch: 4.1023\n",
      "Epoch 3/3\n",
      "409/409 [==============================] - 21s 51ms/step - loss: 3.1742 - recall_at_4: 0.5836 - mrr_at_4: 0.4657 - ndcg_at_4: 0.4956 - map_at_4: 0.4657 - precision_at_4: 0.1459 - regularization_loss: 0.0000e+00 - loss_batch: 3.1731\n",
      "CPU times: user 1min 27s, sys: 13.5 s, total: 1min 41s\n",
      "Wall time: 1min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7ee9e0d3a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_transformer.compile(run_eagerly=False, optimizer=optimizer, loss=\"categorical_crossentropy\",\n",
    "              metrics=mm.TopKMetricsAggregator.default_metrics(top_ks=[4])\n",
    "             )\n",
    "model_transformer.fit(train, batch_size=512, epochs=3, pre=mm.SequencePredictNext(schema=seq_schema, target=target, transformer=xlnet_block))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f2df78-de69-4784-a4ba-070bec015cbd",
   "metadata": {},
   "source": [
    "We will mask the last item using `SequencePredictLast` and perform evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "643fdac2-52f5-4b8f-b818-85564d2ef271",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_last = mm.SequencePredictLast(schema=seq_schema, target=target, transformer=xlnet_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99699e36-2f4e-4bf3-84ef-049d652298fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.schema = train.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c3b6cbd-dd26-4317-8160-2222b77d08fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 5s 35ms/step - loss: 3.5762 - recall_at_4: 0.5431 - mrr_at_4: 0.3767 - ndcg_at_4: 0.4187 - map_at_4: 0.3767 - precision_at_4: 0.1358 - regularization_loss: 0.0000e+00 - loss_batch: 3.5685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 3.576197624206543,\n",
       " 'recall_at_4': 0.542291522026062,\n",
       " 'mrr_at_4': 0.37504497170448303,\n",
       " 'ndcg_at_4': 0.417227566242218,\n",
       " 'map_at_4': 0.37504497170448303,\n",
       " 'precision_at_4': 0.1355728805065155,\n",
       " 'regularization_loss': 0.0,\n",
       " 'loss_batch': 3.534959077835083}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_transformer.evaluate(\n",
    "    valid,\n",
    "    batch_size=1024,\n",
    "    pre=predict_last,\n",
    "    return_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6931a9c9-ed25-4059-b6d1-f425978bb09f",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ca1128-6eb0-4f8f-96bc-3c2ab63d2581",
   "metadata": {},
   "source": [
    "Congratulations on finishing this tutorial. We have walked you through how to tackle with a next-item prediction task using a publicly available dataset. We expect you gained hands-on experience in this tutorial, and you can take this knowledge back to your organizations to build custom accelerated sesion-based recommender models.\n",
    "\n",
    "We demonstrated how one can start with data analysis step first, and prepare the data, transform it and create new features, afterwards, and finally start building models and train/evaluate them using the prepared sequential input dataset.\n",
    "\n",
    "We introduced the NVIDIA Merlin Framework, particularly [NVTabular](https://github.com/NVIDIA-Merlin/NVTabular) and [Models](https://github.com/NVIDIA-Merlin/models) library. Merlin Models session-based TF API is an open source library designed to enable RecSys community quickly and easily explore the ML models or latest developments of the NLP for sequential and session-based recommendation tasks. We experienced how easy it is to build models for session-based tasks using Models high-level APIs.\n",
    "\n",
    "Note that we did not explore hyper-parameter tuning or extensive feature engineering. Following are some additional techniques that can be applied to improve the accuracy metrics:\n",
    "\n",
    "- Data Augmentations - in the [WSDM'21 Booking challenge](https://web.ec.tuwien.ac.at/webtour21/), we used different techniques to augment the training dataset. The techniques are specific to the dataset and we did not include it in this tutorial\n",
    "- Creating additional features\n",
    "- Hyperparameter Search- we can ran multiple HPO jobs to find the best hyperparameters. The simplest approach could be tuning learning_rate, number of epochs, and batch_size\n",
    "- Adding regularization techniques, or model calibration techniques such as label smoothing, or temperature scaling\n",
    "- Ensembling multiple models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31adfd27-4cf2-4f5e-a0ef-c2b17682c6d6",
   "metadata": {},
   "source": [
    "Please execute the cell below to shut down the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9727856b-d1d3-44a9-b0a1-f8cb384ee439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130af8a1-0eef-41e9-89c6-5b46345102a6",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1784ce2-ff78-459a-b4a1-08964aafdc03",
   "metadata": {},
   "source": [
    "[1] Vaswani, A., et al. (2017). Attention is all you need. In Advances in neural information processing systems (pp. 5998-6008).<br>\n",
    "[2] Understanding XLNet, BorealisAI. Online available: https://www.borealisai.com/en/blog/understanding-xlnet/<br>\n",
    "[3] Gabriel De Souza P. Moreira, et al. (2021). Transformers4Rec: Bridging the Gap between NLP and Sequential / Session-Based Recommendation. RecSys'21. <br>\n",
    "[4] Devlin, Jacob, et al. \"Bert: Pre-training of deep bidirectional transformers for language understanding.\" arXiv preprint arXiv:1810.04805 (2018)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
