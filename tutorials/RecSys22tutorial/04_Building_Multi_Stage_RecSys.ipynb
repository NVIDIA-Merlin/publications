{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f62c3c8c-b14e-4933-8b70-fc5a833f2e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ====="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4cca29-4c9e-411d-8aa8-dd10b7d7aa00",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Building Multi-Stage Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbbc0ed-0253-4f56-a368-a5536c77e8e9",
   "metadata": {},
   "source": [
    "Recommender Systems (RecSys) are the engine of the modern internet and the catalyst for human decisions. Building a recommendation system is challenging because it requires multiple stages (data preprocessing, offline training, item retrieval, filtering, ranking, ordering, etc.) to work together seamlessly and efficiently. The biggest challenges for new practitioners are the lack of understanding around what RecSys look like in the real world, and the gap between examples of simple models and a production-ready end-to-end recommender systems.\n",
    "\n",
    "The figure below represents a four-stage recommender systems. This is more complex process than only training a single model and deploying it, and it is much more realistic and closer to what's happening in the real-world recommender production systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785a0986-4e23-4969-9591-e1a92880c5ed",
   "metadata": {},
   "source": [
    "In this lab, we are going to showcase how we can deploy a four-stage recommender systems using Merlin Systems library easily on Triton Inference Server. Let's go over the concepts in the figure briefly.\n",
    "\n",
    "- **Retrieval:** This is the step to narrow down millions of items into thousands of candidates. We are going to train a Two-Tower item retrieval model to retrieve the relevant top-K candidate items.\n",
    "- **Filtering:** This step is to exclude the already interacted or undesirable items from the candidate items set or to apply business logic rules. Although this is an important step, for this example we skip this step.\n",
    "- **Scoring:** This is also known as ranking. Here the retrieved and filtered candidate items are being scored. We are going to train a ranking model to be able to use at our scoring step.\n",
    "- **Ordering:** At this stage, we can order the final set of items that we want to recommend to the user. Here, weâ€™re able to align the output of the model with business needs, constraints, or criteria.\n",
    "\n",
    "To learn more about the four-stage recommender systems, you can listen to Even Oldridge's [Moving Beyond Recommender Models talk at KDD'21](https://www.youtube.com/watch?v=5qjiY-kLwFY&list=PL65MqKWg6XcrdN4TJV0K1PdLhF_Uq-b43&index=8) and read more in this [blog post](https://eugeneyan.com/writing/system-design-for-discovery/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe7611-8697-487d-983c-a8ec0187f773",
   "metadata": {},
   "source": [
    "**Learning Objectives of this notebook**\n",
    "\n",
    "- Train a ranking and retriveal model with Merlin Models\n",
    "- Export user query tower, user and item features, and item embedding\n",
    "- Create feature store with Feast and register features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b54d3c6-fe6c-4a41-ab5e-c80c92efd91d",
   "metadata": {},
   "source": [
    "**Import Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1423d7a5-1ec7-4c9b-a65d-4ac6216f9817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 23:41:37.244178: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-18 23:41:39.903778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8080 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:06:00.0, compute capability: 7.0\n",
      "2022-08-18 23:41:39.920047: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 7.89G (8472494080 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-08-18 23:41:39.922848: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 7.10G (7625244672 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-08-18 23:41:39.925864: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 6.39G (6862720000 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import glob\n",
    "import cudf \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nvtabular as nvt\n",
    "from nvtabular.ops import *\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "from merlin.schema.tags import Tags\n",
    "import merlin.models.tf as mm\n",
    "from merlin.io.dataset import Dataset\n",
    "from merlin.models.utils.dataset import unique_rows_by_features\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a85c3587-4c2f-41b8-bf64-a15a6fe73c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8efaea78-8cc2-4483-a200-21fbb88f1125",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/workspace/data/ecom/'\n",
    "output_path = os.path.join(data_path,'processed_nvt')\n",
    "output_path2 = os.path.join(data_path,'processed_filtered')\n",
    "BASE_DIR = os.environ.get(\n",
    "    \"BASE_DIR\", \"/workspace/recsys_tutorial/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372a3a0c-ba22-4efe-b32b-58b3833cfabd",
   "metadata": {},
   "source": [
    "Read processed parquet files as Dataset objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a8f783-91e9-4890-801b-46adfe504d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/cudf/core/frame.py:384: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_raw = Dataset(os.path.join(output_path, \"train\", \"*.parquet\"), part_size=\"500MB\")\n",
    "valid_raw = Dataset(os.path.join(output_path, \"valid\", \"*.parquet\"), part_size=\"500MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb6887b-837b-4fcf-a1f6-89cce471c6c4",
   "metadata": {},
   "source": [
    "**Filter out the negative rows**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ae7831-e49d-4d6e-a17d-134dab829cae",
   "metadata": {},
   "source": [
    "Here, we will filter our datasets with NVTabular `Filter()` operator to select only positive interaction rows where `target==1` in the dataset. We do that because we want to use `negative sampling` technique when training our candidate retrieval and ranking models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aad817f-cf39-41a6-bd55-5a68b0e5194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = train_raw.schema.column_names\n",
    "outputs = inputs >> Filter(f=lambda df: df[\"target\"] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e46a7e12-d840-4ddd-804a-f9d9b3c6aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow2 = nvt.Workflow(outputs)\n",
    "\n",
    "workflow2.fit(train_raw)\n",
    "\n",
    "workflow2.transform(train_raw).to_parquet(\n",
    "    output_path=os.path.join(output_path2, \"train\")\n",
    ")\n",
    "\n",
    "workflow2.transform(valid_raw).to_parquet(\n",
    "    output_path=os.path.join(output_path2, \"valid\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4143efd7-deb6-4a31-bb03-4a6d6a1e2357",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow2.save(os.path.join(output_path2, \"workflow2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b862799-33d9-471f-9c3e-32878a244f37",
   "metadata": {},
   "source": [
    "**Read filtered parquet files as Dataset objects.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "407a234f-a53c-4624-820a-ceba9d43a7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/cudf/core/frame.py:384: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train = Dataset(os.path.join(output_path2, \"train\", \"*.parquet\"), part_size=\"500MB\")\n",
    "valid = Dataset(os.path.join(output_path2, \"valid\", \"*.parquet\"), part_size=\"500MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "278067af-88fa-4187-adf4-9f12904988a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.start_index</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_id</td>\n",
       "      <td>(Tags.USER_ID, Tags.CATEGORICAL, Tags.USER)</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.user_id.parquet</td>\n",
       "      <td>351050.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>351050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ts_weekday</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.USER)</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.ts_weekday.parquet</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ts_hour</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.USER)</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.ts_hour.parquet</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>product_id</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.ITEM, Tags.ITEM_ID)</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.product_id.parquet</td>\n",
       "      <td>51425.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat_0</td>\n",
       "      <td>(Tags.ITEM, Tags.CATEGORICAL)</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.cat_0.parquet</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cat_1</td>\n",
       "      <td>(Tags.ITEM, Tags.CATEGORICAL)</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.cat_1.parquet</td>\n",
       "      <td>61.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cat_2</td>\n",
       "      <td>(Tags.ITEM, Tags.CATEGORICAL)</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.cat_2.parquet</td>\n",
       "      <td>90.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>brand</td>\n",
       "      <td>(Tags.ITEM, Tags.CATEGORICAL)</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.brand.parquet</td>\n",
       "      <td>2654.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>price</td>\n",
       "      <td>(Tags.ITEM, Tags.CONTINUOUS)</td>\n",
       "      <td>float32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>relative_price</td>\n",
       "      <td>(Tags.ITEM, Tags.CONTINUOUS)</td>\n",
       "      <td>float32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TE_user_id_target</td>\n",
       "      <td>(Tags.ITEM, Tags.CONTINUOUS)</td>\n",
       "      <td>float32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TE_brand_target</td>\n",
       "      <td>(Tags.ITEM, Tags.CONTINUOUS)</td>\n",
       "      <td>float32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TE_cat_1_target</td>\n",
       "      <td>(Tags.ITEM, Tags.CONTINUOUS)</td>\n",
       "      <td>float32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TE_cat_2_target</td>\n",
       "      <td>(Tags.ITEM, Tags.CONTINUOUS)</td>\n",
       "      <td>float32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>event_time_ts</td>\n",
       "      <td>(Tags.TIME)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>target</td>\n",
       "      <td>(Tags.BINARY_CLASSIFICATION, Tags.TARGET)</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'user_id', 'tags': {<Tags.USER_ID: 'user_id'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.USER: 'user'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.user_id.parquet', 'embedding_sizes': {'cardinality': 351050.0, 'dimension': 512.0}, 'domain': {'min': 0, 'max': 351050}}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}, {'name': 'ts_weekday', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.USER: 'user'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.ts_weekday.parquet', 'embedding_sizes': {'cardinality': 8.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 8}}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}, {'name': 'ts_hour', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.USER: 'user'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.ts_hour.parquet', 'embedding_sizes': {'cardinality': 25.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 25}}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}, {'name': 'product_id', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.ITEM: 'item'>, <Tags.ITEM_ID: 'item_id'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.product_id.parquet', 'embedding_sizes': {'cardinality': 51425.0, 'dimension': 512.0}, 'domain': {'min': 0, 'max': 51425}}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}, {'name': 'cat_0', 'tags': {<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.cat_0.parquet', 'embedding_sizes': {'cardinality': 14.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 14}}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}, {'name': 'cat_1', 'tags': {<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.cat_1.parquet', 'embedding_sizes': {'cardinality': 61.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 61}}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}, {'name': 'cat_2', 'tags': {<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.cat_2.parquet', 'embedding_sizes': {'cardinality': 90.0, 'dimension': 20.0}, 'domain': {'min': 0, 'max': 90}}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}, {'name': 'brand', 'tags': {<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.brand.parquet', 'embedding_sizes': {'cardinality': 2654.0, 'dimension': 132.0}, 'domain': {'min': 0, 'max': 2654}}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}, {'name': 'price', 'tags': {<Tags.ITEM: 'item'>, <Tags.CONTINUOUS: 'continuous'>}, 'properties': {}, 'dtype': dtype('float32'), 'is_list': False, 'is_ragged': False}, {'name': 'relative_price', 'tags': {<Tags.ITEM: 'item'>, <Tags.CONTINUOUS: 'continuous'>}, 'properties': {}, 'dtype': dtype('float32'), 'is_list': False, 'is_ragged': False}, {'name': 'TE_user_id_target', 'tags': {<Tags.ITEM: 'item'>, <Tags.CONTINUOUS: 'continuous'>}, 'properties': {}, 'dtype': dtype('float32'), 'is_list': False, 'is_ragged': False}, {'name': 'TE_brand_target', 'tags': {<Tags.ITEM: 'item'>, <Tags.CONTINUOUS: 'continuous'>}, 'properties': {}, 'dtype': dtype('float32'), 'is_list': False, 'is_ragged': False}, {'name': 'TE_cat_1_target', 'tags': {<Tags.ITEM: 'item'>, <Tags.CONTINUOUS: 'continuous'>}, 'properties': {}, 'dtype': dtype('float32'), 'is_list': False, 'is_ragged': False}, {'name': 'TE_cat_2_target', 'tags': {<Tags.ITEM: 'item'>, <Tags.CONTINUOUS: 'continuous'>}, 'properties': {}, 'dtype': dtype('float32'), 'is_list': False, 'is_ragged': False}, {'name': 'event_time_ts', 'tags': {<Tags.TIME: 'time'>}, 'properties': {}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'target', 'tags': {<Tags.BINARY_CLASSIFICATION: 'binary_classification'>, <Tags.TARGET: 'target'>}, 'properties': {}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cb8a3b-e60e-4815-9d72-c7d0e6c6ca6f",
   "metadata": {},
   "source": [
    "### Building and Training a Candidate Retrieval Model with Merlin Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c045cb-ded5-479a-80b4-6b0d0ebc5ea9",
   "metadata": {},
   "source": [
    "Industrial recommender systems have major tasks to accomplish that can be quite demanding. One requirement is to deliver a recommendation under the expected latency requirements (e.g., within milliseconds) to warrant a good user experience. That might require a significant amount of creativity and engineering. And the second consideration is that we might want to minimize infrastructure costs while solving the latency issue, which is yet another obstacle to overcome!\n",
    "\n",
    "In large scale recommender systems pipelines, the size of the item catalog (number of unique items) might be in the order of millions or billions. At such scale, a typical setup is having two-stage pipeline, where a faster candidate retrieval model quickly extracts thousands of relevant items and a then a more powerful ranking model (i.e. with more features and more powerful architecture) ranks the top-k items that are going to be displayed to the user. \n",
    "\n",
    "Therefore, industrial recommender systems usually consists of candidate retrieval and ranking (scoring) stages. The candidate retrieval stage retrieves candidate items that are relevant to user interests, while the ranking stage sorts candidate items by user interests.\n",
    "\n",
    "In this notebook, we start with the first stage of multi-stage recommender systems- the Candidate Retrieval. For ML-based candidate retrieval model, as it needs to quickly score millions of items for a given user, a popular choices are models that can produce recommendation scores by just computing the dot product the user embeddings and item embeddings. Popular choices of such models are `Matrix Factorization (MF)`, which learns low-rank user and item embeddings, and the `Two-Tower architecture`, which is a neural network with two MLP towers where both user and item features are fed to generate user and item embeddings in the output. Such models can be efficiently served by indexing the trained item embeddings into an Approximate Nearest Neighbors (ANN) engine and during inference scoring user embeddings over all indexed item embeddings within the engine. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed922c-dd44-4a7a-8ee5-1275f7970150",
   "metadata": {},
   "source": [
    "#### Two-Tower Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2e80f4-81f9-47dd-9f01-602beec467f0",
   "metadata": {},
   "source": [
    "We are going to train a Two-Tower model for item retrieval. A Two-Tower Model consists of item (candidate) and user (query) encoder towers. With two towers, the model can learn representations (embeddings) for queries and candidates separately.\n",
    "\n",
    "--- ADD IMAGE---\n",
    "\n",
    "Now, let's build our Two-Tower model. In a nutshell, we aggregate all user features to feed in user tower and feed the item features to the item tower. Then we compute the positive score by multiplying the user embedding with the item embedding and sample negative items (read more about negative sampling here and here), whose item embeddings are also multiplied by the user embedding. Then we apply the loss function on top of the positive and negative scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d032c486-3d9b-44f4-af5c-a290157b33cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = train.schema\n",
    "schema = schema.select_by_tag([Tags.ITEM_ID, Tags.USER_ID, Tags.ITEM, Tags.USER])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc38b1c7-a743-42f1-817e-99baa60a4920",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tt = mm.TwoTowerModel(\n",
    "    schema,\n",
    "    query_tower=mm.MLPBlock([128, 64], no_activation_last_layer=True),\n",
    "    samplers=[mm.InBatchSampler()],\n",
    "    embedding_options=mm.EmbeddingOptions(infer_embedding_sizes=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd29fce9-e3ea-49d3-b080-1fe10143ae14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f2089c3c640>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f2089c3c640>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The sampler InBatchSampler returned no samples for this batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/191 [============================>.] - ETA: 0s - loss: 8.4344 - recall_at_10: 0.0168 - ndcg_at_10: 0.0149 - regularization_loss: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The sampler InBatchSampler returned no samples for this batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 30s 58ms/step - loss: 8.4353 - recall_at_10: 0.0169 - ndcg_at_10: 0.0150 - regularization_loss: 0.0000e+00 - val_loss: 8.3632 - val_recall_at_10: 0.0108 - val_ndcg_at_10: 0.0062 - val_regularization_loss: 0.0000e+00\n",
      "Epoch 2/2\n",
      "191/191 [==============================] - 10s 49ms/step - loss: 7.6621 - recall_at_10: 0.0368 - ndcg_at_10: 0.0279 - regularization_loss: 0.0000e+00 - val_loss: 8.2335 - val_recall_at_10: 0.0165 - val_ndcg_at_10: 0.0087 - val_regularization_loss: 0.0000e+00\n",
      "CPU times: user 1min 47s, sys: 4.9 s, total: 1min 52s\n",
      "Wall time: 42.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1c14e69af0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_tt.compile(\n",
    "    optimizer=\"adam\",\n",
    "    run_eagerly=False,\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[mm.RecallAt(10), mm.NDCGAt(10)],\n",
    ")\n",
    "model_tt.fit(train, validation_data=valid, batch_size=1024 * 8, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958bac45-2d09-473a-b32e-26f5c04471eb",
   "metadata": {},
   "source": [
    "#### Exporting query (user) model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb41840-acd3-4f04-9a50-f5133ce05d2c",
   "metadata": {},
   "source": [
    "We export the query tower to use it later during the model deployment stage with Merlin Systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5c75f14-1116-4ae6-8648-2faeb1f8f48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, parallel_block_1_layer_call_fn, parallel_block_1_layer_call_and_return_conditional_losses, sequential_block_3_layer_call_fn while saving (showing 5 of 38). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /workspace/recsys_tutorial/query_tower/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /workspace/recsys_tutorial/query_tower/assets\n"
     ]
    }
   ],
   "source": [
    "query_tower = model_tt.retrieval_block.query_block()\n",
    "query_tower.save(os.path.join(BASE_DIR, \"query_tower\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbb593a-7630-415b-a4ca-707d4821885d",
   "metadata": {},
   "source": [
    "### Train a ranking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a42ee551-8bef-44db-9ba0-93105f19ba3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'target'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = train.schema.without(['event_time_ts'])\n",
    "target_column = schema.select_by_tag(Tags.TARGET).column_names[0]\n",
    "target_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a909456-3b7d-4000-8cc5-73d75ce22b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the batch of positive interactions with `n_per_positive` negatives sampled from the same batch. \n",
    "from merlin.models.tf.data_augmentation.negative_sampling import UniformNegativeSampling\n",
    "from merlin.models.tf.dataset import BatchedDataset\n",
    "\n",
    "batch_size, n_per_positive = 2048, 8\n",
    "add_negatives = UniformNegativeSampling(schema, n_per_positive, seed=42, return_tuple=True)\n",
    "dataset = BatchedDataset(train, batch_size=batch_size, shuffle=True)\n",
    "dataset = dataset.map(add_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5971c399-52a2-4453-b20d-38521ecae8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1557666\n",
       "Name: target, dtype: int32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.to_ddf().compute().target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5aaa2313-e1cd-491a-92dc-bed30a8aa19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mm.DLRMModel(\n",
    "    schema,\n",
    "    embedding_dim=32,\n",
    "    bottom_block=mm.MLPBlock([64, 32]),\n",
    "    top_block=mm.MLPBlock([64, 32]),\n",
    "    prediction_tasks=mm.BinaryClassificationTask(target_column),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc08e20e-4892-49cf-ac12-55f010e71644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761/761 [==============================] - 56s 66ms/step - loss: 0.3232 - binary_accuracy: 0.8046 - auc: 0.6624 - regularization_loss: 0.0000e+00\n",
      "CPU times: user 1min 13s, sys: 5.18 s, total: 1min 18s\n",
      "Wall time: 56.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1c07631b50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.compile(optimizer='adam', run_eagerly=False, metrics=[], \n",
    "              weighted_metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.AUC()]\n",
    "             )\n",
    "model.fit(dataset, epochs=1, train_metrics_steps=100, run_eagerly=False)\n",
    "#model.fit(dataset, epochs=2, class_weight = {0: 1, 1: n_per_positive}, train_metrics_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f38f2daa-d395-4a14-a9d4-99835ca6632a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 4s 64ms/step - loss: 0.3155 - binary_accuracy: 0.8825 - auc: 0.7689 - regularization_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.31547340750694275,\n",
       " 'binary_accuracy': 0.8824513554573059,\n",
       " 'auc': 0.7688804864883423,\n",
       " 'regularization_loss': 0.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset = BatchedDataset(valid, shuffle=False, batch_size = batch_size)\n",
    "valid_dataset = valid_dataset.map(add_negatives)\n",
    "metrics = model.evaluate(valid_dataset, return_dict=True)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5230917a-93f1-43e1-a24e-8ecff0a29800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) TE_brand_target, TE_cat_1_target, TE_cat_2_target, TE_user_id_target with unsupported characters which will be renamed to te_brand_target, te_cat_1_target, te_cat_2_target, te_user_id_target in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as model_context_1_layer_call_fn, model_context_1_layer_call_and_return_conditional_losses, output_layer_layer_call_fn, output_layer_layer_call_and_return_conditional_losses, prediction_layer_call_fn while saving (showing 5 of 84). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /workspace/recsys_tutorial/dlrm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /workspace/recsys_tutorial/dlrm/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(os.path.join(BASE_DIR, \"dlrm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1491b987-1986-4293-b0f2-ad28ecab5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded = tf.keras.models.load_model(os.path.join(BASE_DIR, \"dlrm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bee52ee4-0247-4d5b-aa52-85c79650c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_signature = reloaded.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13406c67-d6dc-4426-b833-12bec4a0b85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction signature_wrapper(*, TE_brand_target, TE_cat_1_target, TE_cat_2_target, TE_user_id_target, brand, cat_0, cat_1, cat_2, price, product_id, relative_price, ts_hour, ts_weekday, user_id) at 0x7F25D8725040>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32593752-e229-44f0-9a01-b26b6a20fed3",
   "metadata": {},
   "source": [
    "#### Set up a feature store with Feast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94e871f2-67c4-477c-892c-e23f65d0450b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating a new Feast repository in \u001b[1m\u001b[32m/workspace/recsys_tutorial/feature_repo\u001b[0m.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm -rf $BASE_DIR/feature_repo\n",
    "!cd $BASE_DIR && feast init feature_repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6301fbd4-0f74-4013-b5a0-0bd5386d3f3a",
   "metadata": {},
   "source": [
    "Feast is an open source project that collects anonymized error reporting and usage statistics. To opt out or learn more see https://docs.feast.dev/reference/usage\n",
    "\n",
    "Creating a new Feast repository in /Merlin/examples/Building-and-deploying-multi-stage-RecSys/feature_repo.\n",
    "\n",
    "You should be seeing a message like Creating a new Feast repository in ... printed out above. Now, navigate to the feature_repo folder and remove the demo parquet file created by default, and examples.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5eaaa0e-aa8b-45af-bbd4-198776bf6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_repo_path = os.path.join(BASE_DIR, \"feature_repo\")\n",
    "if os.path.exists(f\"{feature_repo_path}/example.py\"):\n",
    "    os.remove(f\"{feature_repo_path}/example.py\")\n",
    "if os.path.exists(f\"{feature_repo_path}/data/driver_stats.parquet\"):\n",
    "    os.remove(f\"{feature_repo_path}/data/driver_stats.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b935ad48-0598-4076-855c-285a69f15477",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = (\n",
    "    unique_rows_by_features(train_raw, [Tags.USER,Tags.TIME], Tags.USER_ID)\n",
    "    .compute()\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aaf5848d-d62a-41da-83c2-52e901a6a4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351049, 351049)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.user_id.nunique(), user_features.user_id.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3419701-ac4e-4e86-873e-5af2d32b1a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features[\"datetime\"] = user_features[\"event_time_ts\"].astype(\"datetime64[ns]\")\n",
    "user_features[\"created\"] = datetime.now()\n",
    "user_features[\"created\"] = user_features[\"created\"].astype(\"datetime64[ns]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3107b61f-6415-493c-84cc-581f3ebb5f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = user_features.drop(columns=['event_time_ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d242721a-e26f-497f-9b76-6928440e9046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ts_weekday</th>\n",
       "      <th>ts_hour</th>\n",
       "      <th>datetime</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-03-15 11:47:05</td>\n",
       "      <td>2022-08-18 23:22:26.096830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-03-29 13:19:05</td>\n",
       "      <td>2022-08-18 23:22:26.096830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-21 08:28:23</td>\n",
       "      <td>2022-08-18 23:22:26.096830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-03-29 11:14:14</td>\n",
       "      <td>2022-08-18 23:22:26.096830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2019-12-26 12:14:27</td>\n",
       "      <td>2022-08-18 23:22:26.096830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  ts_weekday  ts_hour            datetime                    created\n",
       "0        1           2        6 2020-03-15 11:47:05 2022-08-18 23:22:26.096830\n",
       "1        2           2        9 2020-03-29 13:19:05 2022-08-18 23:22:26.096830\n",
       "2        3           3        1 2020-03-21 08:28:23 2022-08-18 23:22:26.096830\n",
       "3        4           2        6 2020-03-29 11:14:14 2022-08-18 23:22:26.096830\n",
       "4        5           6        8 2019-12-26 12:14:27 2022-08-18 23:22:26.096830"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f48ba771-1103-4fe8-91fc-81940f8f95d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features.to_parquet(\n",
    "    os.path.join(BASE_DIR, \"feature_repo/data\", \"user_features.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24f2ae74-0cc0-47bd-9541-e049f389b002",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = (\n",
    "    unique_rows_by_features(train_raw, [Tags.ITEM, Tags.TIME], Tags.ITEM_ID)\n",
    "    .compute()\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14bb74cf-94b4-4b5a-864f-580bb9bc46df",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features[\"datetime\"] = item_features[\"event_time_ts\"].astype(\"datetime64[ns]\")\n",
    "item_features[\"created\"] = datetime.now()\n",
    "item_features[\"created\"] = item_features[\"created\"].astype(\"datetime64[ns]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25fc4ad9-12d9-4833-9077-de0c4b401b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = item_features.drop(columns=['event_time_ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "294c0a26-6257-43c1-9397-d46e44bfcfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>cat_0</th>\n",
       "      <th>cat_1</th>\n",
       "      <th>cat_2</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>relative_price</th>\n",
       "      <th>TE_user_id_target</th>\n",
       "      <th>TE_brand_target</th>\n",
       "      <th>TE_cat_1_target</th>\n",
       "      <th>TE_cat_2_target</th>\n",
       "      <th>datetime</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.470813</td>\n",
       "      <td>0.057298</td>\n",
       "      <td>0.377244</td>\n",
       "      <td>0.520552</td>\n",
       "      <td>0.572554</td>\n",
       "      <td>0.909697</td>\n",
       "      <td>2020-03-31 16:24:49</td>\n",
       "      <td>2022-08-18 23:23:11.983316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.543032</td>\n",
       "      <td>0.084794</td>\n",
       "      <td>-0.895478</td>\n",
       "      <td>0.451823</td>\n",
       "      <td>0.571428</td>\n",
       "      <td>0.908887</td>\n",
       "      <td>2020-03-31 14:33:00</td>\n",
       "      <td>2022-08-18 23:23:11.983316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  cat_0  cat_1  cat_2  brand     price  relative_price  \\\n",
       "0           1      1      1      1      1  0.470813        0.057298   \n",
       "1           2      1      1      1      2  1.543032        0.084794   \n",
       "\n",
       "   TE_user_id_target  TE_brand_target  TE_cat_1_target  TE_cat_2_target  \\\n",
       "0           0.377244         0.520552         0.572554         0.909697   \n",
       "1          -0.895478         0.451823         0.571428         0.908887   \n",
       "\n",
       "             datetime                    created  \n",
       "0 2020-03-31 16:24:49 2022-08-18 23:23:11.983316  \n",
       "1 2020-03-31 14:33:00 2022-08-18 23:23:11.983316  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c85ae0c2-220c-41db-9beb-cf93a204b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk\n",
    "item_features.to_parquet(\n",
    "    os.path.join(BASE_DIR, \"feature_repo/data\", \"item_features.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d5c3d71-40f5-4bfe-abc3-0fb9ee206909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) TE_brand_target, TE_cat_1_target, TE_cat_2_target, TE_user_id_target with unsupported characters which will be renamed to te_brand_target, te_cat_1_target, te_cat_2_target, te_user_id_target in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, parallel_block_layer_call_fn, parallel_block_layer_call_and_return_conditional_losses, sequential_block_4_layer_call_fn while saving (showing 5 of 42). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpea4gdz0r/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpea4gdz0r/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "item_embs = model_tt.item_embeddings(\n",
    "    Dataset(item_features, schema=schema), batch_size=1024\n",
    ")\n",
    "item_embs_df = item_embs.compute(scheduler=\"synchronous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d66d1335-2129-4df8-ba6f-f4524790252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only item_id together with embedding columns\n",
    "item_embeddings = item_embs_df.drop(\n",
    "    columns=['cat_0', 'cat_1', 'cat_2', 'brand', 'price',\n",
    "       'relative_price', 'TE_user_id_target', 'TE_brand_target',\n",
    "       'TE_cat_1_target', 'TE_cat_2_target']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8287eba-6ab3-483f-8d40-726040227763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.147541</td>\n",
       "      <td>-0.420399</td>\n",
       "      <td>-0.180685</td>\n",
       "      <td>0.772281</td>\n",
       "      <td>0.376931</td>\n",
       "      <td>-0.02216</td>\n",
       "      <td>-0.074293</td>\n",
       "      <td>-0.689154</td>\n",
       "      <td>0.428960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.977655</td>\n",
       "      <td>-0.262428</td>\n",
       "      <td>-0.855970</td>\n",
       "      <td>0.273959</td>\n",
       "      <td>-0.703504</td>\n",
       "      <td>-0.625795</td>\n",
       "      <td>-0.210638</td>\n",
       "      <td>0.019891</td>\n",
       "      <td>-2.096206</td>\n",
       "      <td>-1.192018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.215549</td>\n",
       "      <td>-0.417371</td>\n",
       "      <td>-0.870647</td>\n",
       "      <td>0.428005</td>\n",
       "      <td>-0.395210</td>\n",
       "      <td>-0.52977</td>\n",
       "      <td>0.713359</td>\n",
       "      <td>0.318280</td>\n",
       "      <td>1.491366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628782</td>\n",
       "      <td>0.439529</td>\n",
       "      <td>-0.311931</td>\n",
       "      <td>-1.121799</td>\n",
       "      <td>-0.008436</td>\n",
       "      <td>-0.649124</td>\n",
       "      <td>0.583354</td>\n",
       "      <td>-0.175015</td>\n",
       "      <td>-2.881193</td>\n",
       "      <td>-1.822508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id         0         1         2         3         4        5  \\\n",
       "0           1 -0.147541 -0.420399 -0.180685  0.772281  0.376931 -0.02216   \n",
       "1           2 -0.215549 -0.417371 -0.870647  0.428005 -0.395210 -0.52977   \n",
       "\n",
       "          6         7         8  ...        54        55        56        57  \\\n",
       "0 -0.074293 -0.689154  0.428960  ... -0.977655 -0.262428 -0.855970  0.273959   \n",
       "1  0.713359  0.318280  1.491366  ...  0.628782  0.439529 -0.311931 -1.121799   \n",
       "\n",
       "         58        59        60        61        62        63  \n",
       "0 -0.703504 -0.625795 -0.210638  0.019891 -2.096206 -1.192018  \n",
       "1 -0.008436 -0.649124  0.583354 -0.175015 -2.881193 -1.822508  \n",
       "\n",
       "[2 rows x 65 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_embeddings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "631ff4b6-3c32-4033-9263-c610cb39d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk\n",
    "item_embeddings.to_parquet(os.path.join(BASE_DIR, \"item_embeddings.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a34912-3bd1-4182-b8e7-2ac5d46ba875",
   "metadata": {},
   "source": [
    "### Create feature definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ff22ad-f280-48e9-985e-f71ddf297f44",
   "metadata": {},
   "source": [
    "Now we will create our user and item features definitions in the user_features.py and item_features.py files and save these files in the feature_repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d82acf7-2c95-498f-8d7d-da7bc613a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(BASE_DIR, \"feature_repo/\", \"user_features.py\"), \"w\")\n",
    "file.write(\n",
    "    \"\"\"\n",
    "from google.protobuf.duration_pb2 import Duration\n",
    "import datetime\n",
    "from feast import Entity, Feature, FeatureView, ValueType\n",
    "from feast.infra.offline_stores.file_source import FileSource\n",
    "\n",
    "user_features = FileSource(\n",
    "    path=\"{}\",\n",
    "    event_timestamp_column=\"datetime\",\n",
    "    created_timestamp_column=\"created\",\n",
    ")\n",
    "\n",
    "user = Entity(name=\"user_id\", value_type=ValueType.INT32, description=\"user id\",)\n",
    "\n",
    "user_features_view = FeatureView(\n",
    "    name=\"user_features\",\n",
    "    entities=[\"user_id\"],\n",
    "    ttl=Duration(seconds=86400 * 7),\n",
    "    features=[\n",
    "        Feature(name=\"ts_weekday\", dtype=ValueType.INT32),\n",
    "        Feature(name=\"ts_hour\", dtype=ValueType.INT32),\n",
    "    ],\n",
    "    online=True,\n",
    "    input=user_features,\n",
    "    tags=dict(),\n",
    ")\n",
    "\"\"\".format(\n",
    "        os.path.join(BASE_DIR, \"feature_repo/data/\", \"user_features.parquet\")\n",
    "    )\n",
    ")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8df12ab8-4d37-4fb2-911c-612353be31bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(BASE_DIR, \"feature_repo/\", \"item_features.py\"), \"w\") as f:\n",
    "    f.write(\n",
    "        \"\"\"\n",
    "from google.protobuf.duration_pb2 import Duration\n",
    "import datetime\n",
    "from feast import Entity, Feature, FeatureView, ValueType\n",
    "from feast.infra.offline_stores.file_source import FileSource\n",
    "\n",
    "item_features = FileSource(\n",
    "    path=\"{}\",\n",
    "    event_timestamp_column=\"datetime\",\n",
    "    created_timestamp_column=\"created\",\n",
    ")\n",
    "\n",
    "item = Entity(name=\"product_id\", value_type=ValueType.INT32, description=\"product id\",)\n",
    "\n",
    "item_features_view = FeatureView(\n",
    "    name=\"item_features\",\n",
    "    entities=[\"product_id\"],\n",
    "    ttl=Duration(seconds=86400 * 7),\n",
    "    features=[\n",
    "        Feature(name=\"cat_0\", dtype=ValueType.INT32),\n",
    "        Feature(name=\"cat_1\", dtype=ValueType.INT32),\n",
    "        Feature(name=\"cat_2\", dtype=ValueType.INT32),\n",
    "        Feature(name=\"brand\", dtype=ValueType.INT32),\n",
    "        Feature(name=\"price\", dtype=ValueType.FLOAT),\n",
    "        Feature(name=\"relative_price\", dtype=ValueType.FLOAT),\n",
    "        Feature(name=\"TE_user_id_target\", dtype=ValueType.FLOAT),\n",
    "        Feature(name=\"TE_brand_target\", dtype=ValueType.FLOAT),\n",
    "        Feature(name=\"TE_cat_1_target\", dtype=ValueType.FLOAT),\n",
    "        Feature(name=\"TE_cat_2_target\", dtype=ValueType.FLOAT),\n",
    "    ],\n",
    "    online=True,\n",
    "    input=item_features,\n",
    "    tags=dict(),\n",
    ")\n",
    "\"\"\".format(\n",
    "            os.path.join(BASE_DIR, \"feature_repo/data/\", \"item_features.parquet\")\n",
    "        )\n",
    "    )\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c502f0-1c0c-4e58-9801-a9b296dba374",
   "metadata": {},
   "source": [
    "### Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e94162-fd41-477b-ab10-f2e603dc6bd2",
   "metadata": {},
   "source": [
    "In this hands-on lab we learned ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
